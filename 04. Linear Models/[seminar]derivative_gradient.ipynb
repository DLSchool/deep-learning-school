{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[seminar]derivative_gradient.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"colab_type":"text","id":"RUWCAY5opP87"},"cell_type":"markdown","source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\"  width=500 height=400></p>\n","\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"metadata":{"colab_type":"text","id":"sEkVD5qHpP89"},"cell_type":"markdown","source":["---"]},{"metadata":{"colab_type":"text","id":"Wj5MrpmRpP89"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Элементы теории оптимизации. Производные и частные производные.</b></h3>"]},{"metadata":{"colab_type":"text","id":"O1xIGzO5pP8-"},"cell_type":"markdown","source":["<p style=\"text-align: center;\">(На основе https://github.com/romasoletskyi/Machine-Learning-Course)</p>"]},{"metadata":{"colab_type":"text","id":"ODaZDX75pP8-"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Приращение линейной функции</b></h3>"]},{"metadata":{"colab_type":"text","id":"tldAx431pP8_"},"cell_type":"markdown","source":["Давайте рассмотрим линейную функцию $y=kx+b$ и построим график: <br>  \n","\n","![source: Wikipedia](https://upload.wikimedia.org/wikipedia/commons/c/c1/Wiki_slope_in_2d.svg) <br>  \n","\n","Введём понятие **приращения** функции в точке $(x, y)$ как отношение вертикального изменения (измненеия функции по вертикали) $\\Delta y$ к горизонтальному изменению $\\Delta x$ и вычислим приращение для линейной функции:  \n","\n","$$приращение (\"slope\")=\\frac{\\Delta y}{\\Delta x}=\\frac{y_2-y_1}{x_2-x_1}=\\frac{kx_2+b-kx_1-b}{x_2-x_1}=k\\frac{x_2-x_1}{x_2-x_1}=k$$  \n","\n","Видим, что приращение в точке у прямой не зависит от $x$ и $\\Delta x$."]},{"metadata":{"colab_type":"text","id":"ObcFoC9JpP9A"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Приращение произвольной функции</b></h3>"]},{"metadata":{"colab_type":"text","id":"dNfWm09WpP9A"},"cell_type":"markdown","source":["Но что, если функция не линейная, а произвольная $f(x)$?  \n","В таком случае просто нарисуем **касательную ** в точке, в которой ищем приращение, и будем смотреть уже на приращение касательной. Так как касательная - это прямая, мы уже знаем, какое у неё приращение (см. выше).\n","![source: Wikipedia](https://upload.wikimedia.org/wikipedia/commons/d/d2/Tangent-calculus.svg)"]},{"metadata":{"colab_type":"text","id":"137KHuBjpP9B"},"cell_type":"markdown","source":["Имея граик функции мы, конечно, можем нарисовать касательную в точке. Но часто функции заданы аналитически, и хочется уметь сразу быстро получать формулу для приращения функциии в точке. Тут на помощь приходит **производная**.  Давайте посмотрим на определение производной его с нашим понятием приращения:  \n","\n","$$f'(x) = \\lim_{\\Delta x \\to 0}\\frac{\\Delta y}{\\Delta x} = \\lim_{\\Delta x \\to 0}\\frac{f(x + \\Delta x) - f(x)}{\\Delta x}$$  \n","\n","То есть по сути, значение производной функции в точке - это и есть приращение функции, если мы стремим длину отрезка $\\Delta x$ к нулю."]},{"metadata":{"colab_type":"text","id":"7YksIkmlpP9C"},"cell_type":"markdown","source":["Посомтрим на интерактивное демо, демонстрирующее стремление $\\Delta x$ к нулю (*в Google Colab работать не будет!*):"]},{"metadata":{"colab_type":"code","id":"v9rhGojJpP9D","colab":{"base_uri":"https://localhost:8080/","height":367},"outputId":"ba6596ca-53ac-45aa-ea53-affe48ac21ac","executionInfo":{"status":"error","timestamp":1540841307892,"user_tz":-180,"elapsed":764,"user":{"displayName":"Илья Дмитриевич Захаркин","photoUrl":"","userId":"09157257912804633784"}}},"cell_type":"code","source":["from __future__ import print_function\n","\n","from ipywidgets import interact, interactive, fixed, interact_manual\n","import ipywidgets as widgets\n","\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-941385be500f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minteract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteract_manual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"colab_type":"code","id":"R4DbxljwpP9F","colab":{}},"cell_type":"code","source":["# pip install ipywidgets"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"RJ_xbrHXpP9I","colab":{}},"cell_type":"code","source":["@interact(lg_z=(-0.5,4.0,0.1))\n","def f(lg_z=1.0):\n","    z = 10 ** lg_z\n","    x_min = 1.5 - 6/z\n","    x_max = 1.5 + 6/z\n","    l_min = 1.5 - 4/z\n","    l_max = 1.5 + 4/z\n","    xstep = (x_max - x_min)/100\n","    lstep = (l_max - l_min)/100\n","    \n","    x = np.arange(x_min, x_max, xstep)\n","    \n","    plt.plot(x, np.sin(x), '-b')     \n","    \n","    plt.plot((l_min,l_max), (np.sin(l_min), np.sin(l_max)), '-r')\n","    plt.plot((l_min,l_max), (np.sin(l_min), np.sin(l_min)), '-r')\n","    plt.plot((l_max,l_max), (np.sin(l_min), np.sin(l_max)), '-r')\n","    \n","    yax = plt.ylim()    \n","    \n","    plt.text(l_max + 0.1/z, (np.sin(l_min) + np.sin(l_max)) / 2, \"$\\Delta y$\")\n","    plt.text((l_min + l_max)/2, np.sin(l_min) - (yax[1]-yax[0]) / 20, \"$\\Delta x$\")\n","    \n","    plt.show()\n","    \n","    print('slope =', (np.sin(l_max) - np.sin(l_min)) / (l_max - l_min))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"v8CYa2CRpP9N"},"cell_type":"markdown","source":["Видим, что при уменьшении отрезка $\\Delta x$, значение приращения стабилизируется (перестаёт изменяться). Это число и есть приращение функции в точке, равное проиводной функции в точке. Производную функции $f(x)$ в точке x обознают как $f'(x)$ или как $\\frac{d}{dx}(f(x))$.  "]},{"metadata":{"colab_type":"text","id":"VMwBqnhVpP9N"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Пример вычисления проиводной</b></h3>"]},{"metadata":{"colab_type":"text","id":"JwlAAsznpP9P"},"cell_type":"markdown","source":["Возьмём производную по определению:"]},{"metadata":{"colab_type":"text","id":"6R_rnMsqpP9P"},"cell_type":"markdown","source":["1. $f(x)=x$  \n","\n","$$\\frac{\\Delta y}{\\Delta x}=\\frac{x+\\Delta x-x}{\\Delta x}=1\\Rightarrow \\mathbf{\\frac{d}{dx}(x)=1}$$  \n","\n","2. $f(x)=x^2$  \n","\n","$$\\frac{\\Delta y}{\\Delta x}=\\frac{(x+\\Delta x)^2-x^2}{\\Delta x}=\\frac{x^2+2x\\Delta x+\\Delta x^2-x^2}{\\Delta x}=2x+\\Delta x\\rightarrow 2x (\\Delta x\\rightarrow 0)\\Rightarrow \\mathbf{\\frac{d}{dx}(x^2)=2x}$$  \n","    \n","3. В общем случае для степенной функции $f(x)=x^n$ формула будет такой:  \n","\n","$$\\mathbf{\\frac{d}{dx}(x^n)=nx^{n-1}}$$  "]},{"metadata":{"colab_type":"text","id":"KP4jUOaqpP9P"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Правила вычисления проиводной</b></h3>"]},{"metadata":{"colab_type":"text","id":"8fb0go1lpP9Q"},"cell_type":"markdown","source":["Выпишет правила *дифференцирования*:  \n","\n","1). Если $f(x)$ - константа, то её производная (приращение) 0:  \n","\n","$$(C)' = 0$$\n","\n","2). Производная суммы функций - это сумма производных:  \n","\n","$$(f(x) + g(x))' = f'(x) + g'(x)$$\n","\n","3). Производная разности - разность производных:  \n","\n","$$(f(x) - g(x))' = f'(x) - g'(x)$$\n","\n","4). Производная произведения функций:  \n","\n","$$(f(x)g(x))' = f'(x)g(x) + f(x)g'(x)$$\n","\n","5). Производная частного:  \n","\n","$$\\left(\\frac{f(x)}{g(x)}\\right)'=\\frac{f'(x)g(x)-g'(x)f(x)}{g^2(x)}$$\n","\n","6). Производная сложной функции (\"правило цепочки\", \"chain rule\"):  \n","\n","$$(f(g(x)))'=f'(g(x))g'(x)$$\n","\n","Можно записать ещё так:  \n","\n","$$\\frac{d}{dx}(f(g(x)))=\\frac{df}{dg}\\frac{dg}{dx}$$"]},{"metadata":{"colab_type":"text","id":"ZFTReW5ppP9R"},"cell_type":"markdown","source":["**Примеры**:"]},{"metadata":{"colab_type":"text","id":"grjqr2h4pP9R"},"cell_type":"markdown","source":["* Вычислим производную функции $$f(x) = \\frac{x^2}{cos(x)} + 100$$:  \n","\n","$$f'(x) = \\left(\\frac{x^2}{cos(x)}+100\\right)' = \\left(\\frac{x^2}{cos(x)}\\right)' + (100)' = \\frac{(2x)\\cos(x) - x^2(-\\sin(x))}{cos^2(x)}$$"]},{"metadata":{"colab_type":"text","id":"TSqCaSSYpP9T"},"cell_type":"markdown","source":["* Вычислим производную функции $$f(x) = tg(x)$$:  \n","\n","$$f'(x) = \\left(tg(x)\\right)' = \\left(\\frac{\\sin(x)}{\\cos(x)}\\right)' = \\frac{\\cos(x)\\cos(x) - \\sin(x)(-\\sin(x))}{cos^2(x)} = \\frac{1}{cos^2(x)}$$"]},{"metadata":{"colab_type":"text","id":"FXP_YETzpP9T"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Частные производные</b></h3>"]},{"metadata":{"colab_type":"text","id":"aJDwZBCZpP9T"},"cell_type":"markdown","source":["Когда мы имеем функци многих переменных, её уже сложнее представить себе в виде рисунка (в случае более 3-х переменных это действительно не всем дано). ОДнако формальные правила взятия производной у таких функций созраняются. Они в точности совпадают с тоеми, которые рассмотрены выше для функции одной переменной.  \n","\n","Итак, правило взятия частной производной функции мнгих переменных:  \n","1). Пусть $f(\\overline{x}) = f(x_1, x_2, .., x_n)$ - функция многих переменных;  \n","2). Частная проиводная по $x_i$ это функции - это производная по x_i, считая все остальные переменные **константами**. \n","\n","Более математично:  \n","\n","Частная производная функции $f(x_1,x_2,...,x_n)$ по $x_i$ равна  \n","\n","$$\\frac{\\partial f(x_1,x_2,...,x_n)}{\\partial x_i}=\\frac{df_{x_1,...,x_{i-1},x_{i+1},...x_n}(x_i)}{dx_i}$$  \n","\n","где $f_{x_1,...,x_{i-1},x_{i+1},...x_n}(x_i)$ означает, что переменные $x_1,...,x_{i-1},x_{i+1},...x_n$ - это фиксированные значения, и с ними нужно обращаться как с константами."]},{"metadata":{"colab_type":"text","id":"3uPIkZ-wpP9U"},"cell_type":"markdown","source":["**Примеры**:   "]},{"metadata":{"colab_type":"text","id":"aodpt9VppP9V"},"cell_type":"markdown","source":["* Найдём частные производные функции $f(x, y) = -x^7 + (y - 2)^2 + 140$ по $x$ и по $y$:  \n","\n","$$f_x'(x, y) = \\frac{\\partial{f(x, y)}}{\\partial{x}} = -7x^6$$  \n","$$f_y'(x, y) = \\frac{\\partial{f(x, y)}}{\\partial{y}} = 2(y - 2)$$"]},{"metadata":{"colab_type":"text","id":"3pRitR-YpP9W"},"cell_type":"markdown","source":["* Найдём частные производные функции $f(x, y, z) = \\sin(x)\\cos(y)tg(z)$ по $x$, по $y$ и по $z$:  \n","\n","$$f_x'(x, y) = \\frac{\\partial{f(x, y)}}{\\partial{x}} = \\cos(x)\\cos(y)tg(z)$$  \n","$$f_y'(x, y) = \\frac{\\partial{f(x, y)}}{\\partial{y}} = \\sin(x)(-\\sin(y))tg(z)$$\n","$$f_z'(x, y) = \\frac{\\partial{f(x, y)}}{\\partial{y}} = \\frac{\\sin(x)\\cos(y)}{\\cos^2{z}}$$"]},{"metadata":{"colab_type":"text","id":"nrmPlYyrpP9X"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Градиентный спуск</b></h3>"]},{"metadata":{"colab_type":"text","id":"SeD8U4CApP9X"},"cell_type":"markdown","source":["**Градиентом** функции $f(\\overline{x})$, где $\\overline{x} \\in \\mathbb{R^n}$, то есть $\\overline{x} = (x_1, x_2, .., x_n)$, называется вектор из частных производных функции $f(\\overline{x})$:  \n","\n","$$grad(f) = \\nabla f(\\overline{x}) = \\left(\\frac{\\partial{f(\\overline{x})}}{\\partial{x_1}}, \\frac{\\partial{f(\\overline{x})}}{\\partial{x_2}}, .., \\frac{\\partial{f(\\overline{x})}}{\\partial{x_n}}\\right)$$"]},{"metadata":{"colab_type":"text","id":"DcjYCHOepP9Y"},"cell_type":"markdown","source":["Есть функция $f(x)$. Хотим найти аргумент, при котором она даёт минимум.\n","\n","Алгоритм градиентного спуска:  \n","1. $x^0$ - начальное значение (обычно берётся просто из разумных соображений или случайное);  \n","2. $x^i = x^{i-1} - \\alpha \\nabla f(x^{i-1})$, где $\\nabla f(x^{i-1})$ - это градиент функции $f$, в который подставлено значение $x^{i-1}$;\n","3. Выполнять пункт 2, пока не выполнится условие остановки: $||x^{i} - x^{i-1}|| < eps$, где $||x^{i} - x^{i-1}|| = \\sqrt{(x_1^i - x_1^{i-1})^2 + .. + (x_n^i - x_n^{i-1})^2}$.  "]},{"metadata":{"colab_type":"text","id":"zX1miuQ0pP9Z"},"cell_type":"markdown","source":["**Примеры:**"]},{"metadata":{"colab_type":"text","id":"t1M6agxdpP9Z"},"cell_type":"markdown","source":["* *Пример 1*: Посчитаем формулу градиентного спуска для функции $f(x) = 10x^2$:   "]},{"metadata":{"colab_type":"text","id":"1WMJRqDRpP9a"},"cell_type":"markdown","source":["$x^i = x^{i-1} - \\alpha \\nabla f(x^{i-1}) = x^{i-1} - \\alpha f'(x^{i-1}) = x^{i-1} - \\alpha (20x^{i-1})$"]},{"metadata":{"colab_type":"text","id":"EqjopRZVpP9b"},"cell_type":"markdown","source":["Имея эту формулу, напишем код градиентного спуска для функции $f(x) = 10x^2$:"]},{"metadata":{"colab_type":"code","id":"evLahkyIpP9c","colab":{}},"cell_type":"code","source":["import numpy as np\n","from tqdm import tqdm\n","\n","def f(x):\n","    return 10 * x**2\n","\n","def gradient_descent(alpha=0.001, eps=0.01):\n","    x_pred = 100  # начальная инициализация\n","    x = 50  # начальная инициализация\n","    for _ in tqdm(range(100000)):\n","        print(_)  # смотрим, на каком мы шаге\n","        if np.sum((x - x_pred)**2) < eps**2:  # условие остановки\n","            break\n","        x_pred = x\n","        x = x_pred - 20 * alpha * x_pred  # по формуле выше\n","    return x"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1539764935297,"user_tz":-180,"elapsed":501,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}},"id":"9k8A7ei8pP9g","outputId":"7d0401a9-5810-4215-89af-4a9d077c05eb","colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["x_min = gradient_descent()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/100000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1539764937543,"user_tz":-180,"elapsed":482,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}},"id":"uGOVAybRpP9k","outputId":"2c6d1f12-ce1e-491f-ca98-6e1fe98849c7","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_min"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6.51605e-06"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1539764938543,"user_tz":-180,"elapsed":598,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}},"id":"_EW8AY8VpP9n","outputId":"4d7b79da-706d-4d04-c1ba-29d39625760f","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["f(x_min)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.24589076025e-10"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"colab_type":"text","id":"tsqfsTezpP9q"},"cell_type":"markdown","source":["* *Пример 2*: Посчитаем формулу градиентного спуска для функции $f(x, y) = 10x^2 + y^2$:   "]},{"metadata":{"colab_type":"text","id":"MNWMBcbNpP9r"},"cell_type":"markdown","source":["$$\\left(\\begin{matrix} x^i \\\\ y^i \\end{matrix}\\right) = \\left(\\begin{matrix} x^{i-1} \\\\ y^{i-1} \\end{matrix}\\right) - \\alpha \\nabla f(x^{i-1}, y^{i-1}) = \\left(\\begin{matrix} x^{i-1} \\\\ y^{i-1} \\end{matrix}\\right) - \\alpha \\left(\\begin{matrix} \\frac{\\partial{f(x^{i-1}, y^{i-1})}}{\\partial{x}} \\\\ \\frac{\\partial{f(x^{i-1}, y^{i-1})}}{\\partial{y}} \\end{matrix}\\right) = x^{i-1} - \\alpha \\left(\\begin{matrix} 20x^{i-1} \\\\ 2y^{i-1} \\end{matrix}\\right)$$"]},{"metadata":{"colab_type":"text","id":"sBnijsKLpP9r"},"cell_type":"markdown","source":["Осталось написать код, выполняющий градиентный спуск, пока не выполнится условие остановки, для функции $f(x, y) = 10x^2 + y^2$:"]},{"metadata":{"colab_type":"code","id":"p_rDsja-pP9s","colab":{}},"cell_type":"code","source":["import numpy as np\n","from tqdm import tqdm\n","\n","def f(x):\n","    return 10 * x[0]**2 + x[1]**2\n","\n","def gradient_descent(alpha=0.01, eps=0.001):\n","    x_prev = np.array([100, 100])  # начальная инициализация\n","    x = np.array([50, 50])  # начальная инициализация\n","    for _ in tqdm(range(100000)):\n","        print(_)  # смотрим, на каком мы шаге\n","        if np.sum((x - x_prev)**2) < eps**2:  # условие остановки\n","            break\n","        x_prev = x\n","        x = x_prev - alpha * np.array(20 * x_prev[0], 2 * x_prev[1])  # по формуле выше\n","    return x"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"boueQCnXpP9u","colab":{}},"cell_type":"code","source":["x_min = gradient_descent()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"6pyhQsmXpP9x","colab":{}},"cell_type":"code","source":["x_min"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"ytAfn_X7pP90","colab":{}},"cell_type":"code","source":["f(x_min)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"YyKaCWuJpP93"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Домашнее задание</b></h3>"]},{"metadata":{"colab_type":"text","id":"jrjiC9mUpP93"},"cell_type":"markdown","source":["1). (только для тех, кто раньше брал производные) Вычислите производную функции $f(x)=\\frac{1}{x}$ по определению и сравните с производной степенной функции в общем случае;  \n","2). Найдите производную функции $Cf(x)$, где С - число;  \n","3). Найдите производные функций:  \n","\n","$$f(x)=x^3+3\\sqrt{x}-e^x$$\n","\n","$$f(x)=\\frac{x^2-1}{x^2+1}$$\n","\n","$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n","\n","$$L(y, \\hat{y}) = (y-\\hat{y})^2$$  \n","\n","4). Напишите формулу и код для градиентного спуска для функции:  \n","$$f(w, x) = \\frac{1}{1 + e^{-wx}}$$  \n","\n","То есть по аналогии с примером 2 вычислите частные производные по $w$ и по $x$ и запишите формулу векторно (см. пример 2)\n","\n","В задаче 3 производную нужно брать по $\\hat{y}$."]},{"metadata":{"colab_type":"text","id":"wxDBOB04pP93"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"]},{"metadata":{"colab_type":"text","id":"Nm0VC825pP95"},"cell_type":"markdown","source":["0). Прикольный сайт с рисунками путём задания кривых уравнениями и функциями:  \n","\n","https://www.desmos.com/calculator/jwshvscdzb\n","\n","***Производные:***\n","\n","1). Про то, как брать частные производные:  \n","\n","http://www.mathprofi.ru/chastnye_proizvodnye_primery.html\n","\n","2). Сайт на английском, но там много видеоуроков и задач по производным:  \n","\n","https://www.khanacademy.org/math/differential-calculus/derivative-intro-dc\n","\n","3). Задачи на частные производные:  \n","\n","http://ru.solverbook.com/primery-reshenij/primery-resheniya-chastnyx-proizvodnyx/  \n","\n","4). Ещё задачи на частные проивзодные:  \n","\n","https://xn--24-6kcaa2awqnc8dd.xn--p1ai/chastnye-proizvodnye-funkcii.html  \n","\n","5). Производные по матрицам:  \n","\n","http://nabatchikov.com/blog/view/matrix_der  \n","\n","***Градиентны спуск:***\n","\n","6). [Основная статья по градиентному спуску](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0)\n","\n","7). Статья на Хабре про градиетный спуск для нейросетей:  \n","\n","https://habr.com/post/307312/  \n","\n","***Методы оптимизации в нейронных сетях:***\n","\n","8). Сайт с анимациями того, как сходятся алгоритмы градиентного спуска:\n","www.denizyuret.com/2015/03/alec-radfords-animations-for.html\n","\n","9). Статья на Хабре про метопты (град. спуск) в нейронках:\n","https://habr.com/post/318970/\n","\n","10). Ещё сайт (англ.) про метопты (град. спуск) в нейронках (очень подробно):\n","http://ruder.io/optimizing-gradient-descent/"]}]}