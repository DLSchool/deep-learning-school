{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[seminar]neuron_logloss.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"colab_type":"text","id":"_FclQTtlZca3"},"cell_type":"markdown","source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"metadata":{"colab_type":"text","id":"o1QM-pm7Zca4"},"cell_type":"markdown","source":["---"]},{"metadata":{"colab_type":"text","id":"tWTTy4lrZca5"},"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>Обучение нейрона с помощью функции потерь LogLoss: решение</b></h2>"]},{"metadata":{"colab_type":"text","id":"-80-LkjSZca6"},"cell_type":"markdown","source":["---"]},{"metadata":{"colab_type":"text","id":"VvIHYHMQZca7"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Напоминание</b></h3>"]},{"metadata":{"colab_type":"text","id":"KU9Uf1w2Zca8"},"cell_type":"markdown","source":["Почти любой алгоритм машинного обучения, решающий задачу *классификации* или *регрессии*, работает так:\n","\n","1. (*стадия инициализации*) Задаются его **гиперпараметры**, то есть те величины, которые не \"выучиваются\" алгоритмом в процессе обучения самостоятельно \n","2. (*стадия обучения*) Алгоритм запускается на данных, **обучаясь** на них и меняя свои **параметры** (не путать с *гипер*параметрами) каким-то определённым образом (например, с помощью *метода градиентного спуска*), исходя из функции потерь (её называют *loss function*). Функция потерь, по сути, говорит, где и как ошибается модель\n","3.  (*стадия предсказания*) Модель готова, и теперь с помощью неё можно делать **предсказания** на новых объектах"]},{"metadata":{"colab_type":"text","id":"jdNcqz_wZca9"},"cell_type":"markdown","source":["В даном ноутбуке будет решаться задача **бинарной классификации** с помощью нейрона:  \n","- *Входные данные*: матрица $X$ размера $(n, m)$ и столбец $y$ из нулей и единиц размера $(n, 1)$. Строкам матрицы соответствуют объекты, столбцам - признаки (то есть строка $i$ есть набор признаков (*признаковое описание*) объекта $x_i$).\n","- *Выходные данные*: столбец $\\hat{y}$ из нулей и единиц размера $(n, 1)$ - предсказания алгоритма."]},{"metadata":{"colab_type":"text","id":"fBZn3J6GZca_"},"cell_type":"markdown","source":["Модель нейрона в биологии и в deep learning:  \n","\n","![title](http://lamda.nju.edu.cn/weixs/project/CNNTricks/imgs/neuron.png)"]},{"metadata":{"colab_type":"text","id":"G_zlIW5BZcbB"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Нейрон с сигмоидой</b></h3>"]},{"metadata":{"colab_type":"text","id":"QWwW32pCZcbC"},"cell_type":"markdown","source":["Снова рассмотрим нейрон с сигмоидой, то есть $$f(x) = \\sigma(x)=\\frac{1}{1+e^{-x}}$$ на рисунке выше."]},{"metadata":{"colab_type":"text","collapsed":true,"id":"mj5QizQIZcbC"},"cell_type":"markdown","source":["На предыдущем занятии мы установили, что обучение нейрона с сигмоидой с квадратичной функцией потерь:  \n","\n","$$J(w, x) = \\frac{1}{2n}\\sum_{i=1}^{n} (\\hat{y_i} - y_i)^2 = \\frac{1}{2n}\\sum_{i=1}^{n} (\\sigma(w \\cdot x_i) - y_i)^2$$    \n","\n","где $w \\cdot x_i$ - скалярное произведение, а $\\sigma(w \\cdot x_i) =\\frac{1}{1+e^{-w \\cdot x_i}} $ - сигмоида - **неэффективно**, то есть мы увидели, что даже за большое количество итераций нейрон предсказывает плохо."]},{"metadata":{"colab_type":"text","id":"MTgNbravZcbE"},"cell_type":"markdown","source":["Давайте ещё раз взглянем на формулу для градиентного спуска от функции потерь $J$ по весам нейрона:"]},{"metadata":{"colab_type":"text","collapsed":true,"id":"RHXjByowZcbE"},"cell_type":"markdown","source":["$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{n} X^T (\\sigma(w \\cdot X) - y)\\sigma(w \\cdot X)(1 - \\sigma(w \\cdot X))$$"]},{"metadata":{"colab_type":"text","id":"ebNqrTV3ZcbF"},"cell_type":"markdown","source":["А теперь смотрим на график сигмоиды:"]},{"metadata":{"colab_type":"text","id":"366q3EzJZcbH"},"cell_type":"markdown","source":["<img src=\"https://cdn-images-1.medium.com/max/1200/1*IDAnCFoeXqWL7F4u9MJMtA.png\" width=500px height=350px>"]},{"metadata":{"colab_type":"text","id":"CSEF3EWVZcbJ"},"cell_type":"markdown","source":["**Её значения -- числа от 0 до 1.**"]},{"metadata":{"colab_type":"text","id":"8oOJPcKhZcbJ"},"cell_type":"markdown","source":["Если получше проанализировать формулу, то теперь можно заметить, что, поскольку сигмоида принимает значения между 0 и 1 (а значит (1-$\\sigma$) тоже принимает значения от 0 до 1), то мы умножаем $X^T$ на столбец $(\\sigma(w \\cdot X) - y)$ из чисел от -1 до 1, а потом ещё на столбцы $\\sigma(w \\cdot X)$ и $(1 - \\sigma(w \\cdot X))$ из чисел от 0 до 1. Таким образом в лучшем случае $\\frac{\\partial{J}}{\\partial{w}}$ будет столбцом из чисел, порядок которых максимум 0.01 (в среднем, понятно, что если сигмоида выдаёт все 0, то будет 0, если все 1, то тоже 0). После этого мы умножаем на шаг градиентного спуска, который обычно порядкF 0.001 или 0.01 максимум. То есть мы вычитаем из весов числа порядка ~0.0001. Медленновато спускаемся, не правда ли?"]},{"metadata":{"colab_type":"text","id":"hHmUqm5xZcbK"},"cell_type":"markdown","source":["Всё верно. В задачах классификации, в которых моделью является нейрон с сигмоидной функцией активации, предсказывающий \"вероятности\" принадлженостей к классам, почти никогда не используют квадратичную функцию потерь $J$. Вместо неё придумали другую прекрасную функцию потерь. Просим любить и жаловать, **LogLoss**:  "]},{"metadata":{"colab_type":"text","id":"Dbw69trJZcbL"},"cell_type":"markdown","source":["$$J(\\hat{y}, y) = -\\frac{1}{n} \\sum_{i=1}^n y_i \\log(\\hat{y_i}) + (1 - y_i) \\log(1 - \\hat{y_i}) = -\\frac{1}{n} \\sum_{i=1}^n y_i \\log(\\sigma(w \\cdot x_i)) + (1 - y_i) \\log(1 - \\sigma(w \\cdot x_i))$$"]},{"metadata":{"colab_type":"text","id":"jXcBIx73ZcbM"},"cell_type":"markdown","source":["где, как и прежде, $y$ - столбец $(n, 1)$ из истинных значений классов, а $\\hat{y}$ - столбец $(n, 1)$ из предсказаний нейрона."]},{"metadata":{"colab":{},"colab_type":"code","id":"5DBEOhJmZcbN"},"cell_type":"code","source":["from matplotlib import pyplot as plt\n","from matplotlib.colors import ListedColormap  # тут лежат разные штуки для цветовой магии\n","import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"_x5CX0RyZcbQ"},"cell_type":"code","source":["def J(y_pred, y):\n","    return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"raPTihU6ZcbT"},"cell_type":"markdown","source":["Отметим, что сейчас речь идёт именно о **бинарной классификации (на два класса)**, в многоклассовой классификации используется функция потерь под названием *кросс-энтропия*, которая является обобщением LogLoss'а на случай нескольких классов."]},{"metadata":{"colab_type":"text","id":"uz7UJCW3ZcbU"},"cell_type":"markdown","source":["А почему же теперь всё будет лучше? Раньше была проблема умножения маленьких чисел в градиенте. Давайте посмотрим, что теперь (в формуле ниже $X^T$ написан так для того, чтобы потом сразу стала видна матричная запись, вообще запись \"умножение $X^T$ на сумму из чисел\" здесь некорректна):"]},{"metadata":{"colab_type":"text","id":"ffySAbg_ZcbU"},"cell_type":"markdown","source":["$$ \\frac{\\partial J}{\\partial w} = \n","-\\frac{1}{n} X^T \\sum_{i=1}^n \\left(\\frac{y_i}{\\sigma(w \\cdot x_i)} - \\frac{1 - y_i}{1 - \\sigma(w \\cdot x_i)}\\right)\\sigma'(w \\cdot x_i) = \n","-\\frac{1}{n} X^T \\sum_{i=1}^n \\left(\\frac{y_i}{\\sigma(w \\cdot x_i)} - \\frac{1 - y_i}{1 - \\sigma(w \\cdot x_i)}\\right)\\sigma(w \\cdot x_i)(1 - \\sigma(w \\cdot x_i)) = \\\\\n","=-\\frac{1}{n} X^T \\sum_{i=1}^n \\left(y_i - \\sigma(w \\cdot x_i)\\right) = \n","\\frac{1}{n} X^T \\left(\\hat{y} - y\\right)$$"]},{"metadata":{"colab_type":"text","id":"7HQALb8XZcbU"},"cell_type":"markdown","source":["Получили новое правило для обновления. Интересно.. Но погодите, это же в точности то правило обновления весов для градиентного спуска, которое мы использовали для перцептрона! Получается, что мы пришли к этому правилу \"по-честному\", сделав функцией активации сигмоиду и введя новую функию потерь -- LogLoss, а когда реализовывали перцептрон, мы просто сказали (воспользовавшись *правилом Хебба*), что $f'(x)$ возьмём единицей, то есть тут имеет место интересная связь градиентного спуска и метода коррекции ошибки."]},{"metadata":{"colab_type":"text","id":"3Kr-edseZcbW"},"cell_type":"markdown","source":["Отсюда очевидно, что код для нейрона с такой функцией потерь не будем ничем отличаться от кода для перцептрона, за исключением метода `self.activate()`. Напишем:"]},{"metadata":{"colab":{},"colab_type":"code","id":"xL2gqg27ZcbW"},"cell_type":"code","source":["def sigmoid(x):\n","    \"\"\"Сигмоидальная функция\"\"\"\n","    return 1 / (1 + np.exp(-x))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"ukZ-iJNRZcbY"},"cell_type":"markdown","source":["Реализацем нейрон с функцией потерь LogLoss:"]},{"metadata":{"colab":{},"colab_type":"code","id":"TdnkoJDfZcba"},"cell_type":"code","source":["class Neuron:\n","    def __init__(self, w=None, b=0):\n","        \"\"\"\n","        :param: w -- вектор весов\n","        :param: b -- смещение\n","        \"\"\"\n","        # Пока что мы не знаем размер матрицы X, а значит не знаем, сколько будет весов\n","        self.w = w\n","        self.b = b\n","        \n","    def activate(self, x):\n","        return sigmoid(x)\n","        \n","    def forward_pass(self, X):\n","        \"\"\"\n","        Эта функция рассчитывает ответ нейрона при предъявлении набора объектов\n","        :param: X -- матрица объектов размера (n, m), каждая строка - отдельный объект\n","        :return: вектор размера (n, 1) из нулей и единиц с ответами перцептрона \n","        \"\"\"\n","        n = X.shape[0]\n","        y_pred = np.zeros((n, 1))  # y_pred == y_predicted - предсказанные классы\n","        y_pred = self.activate(X @ self.w.reshape(X.shape[1], 1) + self.b)\n","        return y_pred.reshape(-1, 1)\n","    \n","    def backward_pass(self, X, y, y_pred, learning_rate=1):\n","        \"\"\"\n","        Обновляет значения весов нейрона в соответствии с этим объектом\n","        :param: X -- матрица объектов размера (n, m)\n","                y -- вектор правильных ответов размера (n, 1)\n","                learning_rate - \"скорость обучения\" (символ alpha в формулах выше)\n","        В этом методе ничего возвращать не нужно, только правильно поменять веса\n","        с помощью градиентного спуска.\n","        \"\"\"\n","        n = len(y)\n","        y = np.array(y).reshape(-1, 1)\n","        self.w = self.w - learning_rate * (X.T @ (y_pred - y) / n)\n","        self.b = self.b - learning_rate * np.mean(y_pred - y)\n","    \n","    def fit(self, X, y, num_epochs=5000):\n","        \"\"\"\n","        Спускаемся в минимум\n","        :param: X -- матрица объектов размера (n, m)\n","                y -- вектор правильных ответов размера (n, 1)\n","                num_epochs -- количество итераций обучения\n","        :return: J_values -- вектор значений функции потерь\n","        \"\"\"\n","        self.w = np.zeros((X.shape[1], 1))  # столбец (m, 1)\n","        self.b = 0  # смещение\n","        J_values = []  # значения функции потерь на различных итерациях обновления весов\n","        \n","        for i in range(num_epochs):\n","            # предсказания с текущими весами\n","            y_pred = self.forward_pass(X)\n","            # считаем функцию потерь с текущими весами\n","            J_values.append(J(y_pred, y))\n","            # обновляем веса в соответсвие с тем, где ошиблись раньше\n","            self.backward_pass(X, y, y_pred)\n","\n","        return J_values"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"-RQRPI50Zcbb"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Тестирование</b></h3>"]},{"metadata":{"colab_type":"text","id":"FBwpsQc0Zcbc"},"cell_type":"markdown","source":["Протестируем нейрон, обученный с новой функцией потерь, на тех же данных, что и в предыдущем ноутбуке:"]},{"metadata":{"colab_type":"text","id":"JVCPAAuXZcbd"},"cell_type":"markdown","source":["**Проверка forward_pass()**"]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"hbuAzv_YZcbe","outputId":"95004e10-a72e-4aaf-9929-2589d8722bad","executionInfo":{"status":"ok","timestamp":1539422634948,"user_tz":-300,"elapsed":646,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}}},"cell_type":"code","source":["w = np.array([1., 2.]).reshape(2, 1)\n","b = 2.\n","X = np.array([[1., 3.],\n","              [2., 4.],\n","              [-1., -3.2]])\n","\n","neuron = Neuron(w, b)\n","y_pred = neuron.forward_pass(X)\n","print (\"y_pred = \" + str(y_pred))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["y_pred = [[0.99987661]\n"," [0.99999386]\n"," [0.00449627]]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"eL6viEHNZcbi"},"cell_type":"markdown","source":["**Проверка backward_pass()**"]},{"metadata":{"colab":{},"colab_type":"code","id":"_4F8zActZcbk"},"cell_type":"code","source":["y = np.array([1, 0, 1]).reshape(3, 1)"],"execution_count":0,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","id":"ILDcoLqwZcbm","outputId":"a70db24d-e05a-4a05-d203-77576034aa80","executionInfo":{"status":"ok","timestamp":1539422636670,"user_tz":-300,"elapsed":750,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}}},"cell_type":"code","source":["neuron.backward_pass(X, y, y_pred)\n","\n","print (\"w = \" + str(neuron.w))\n","print (\"b = \" + str(neuron.b))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["w = [[ 0.00154399]\n"," [-0.39507239]]\n","b = 1.9985444218632158\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"_1ZRdKcfZcbq"},"cell_type":"markdown","source":["Загрузим данные (яблоки и груши):"]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":878},"colab_type":"code","id":"RWYeLd-hZcbq","outputId":"343d6ee6-e401-437c-b0c7-2e1dff231edf","executionInfo":{"status":"error","timestamp":1539422637796,"user_tz":-300,"elapsed":996,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}}},"cell_type":"code","source":["data = pd.read_csv(\"./data/apples_pears.csv\")"],"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-1138af4aea66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/apples_pears.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: File b'./data/apples_pears.csv' does not exist"]}]},{"metadata":{"colab":{},"colab_type":"code","id":"9ecudw87Zcbu"},"cell_type":"code","source":["data.head()"],"execution_count":0,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"Wjc26FMiZcbz"},"cell_type":"code","source":["plt.figure(figsize=(10, 8))\n","plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=data['target'], cmap='rainbow')\n","plt.title('Яблоки и груши', fontsize=15)\n","plt.xlabel('симметричность', fontsize=14)\n","plt.ylabel('желтизна', fontsize=14)\n","plt.show();"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"eaTnrIVUZcb1"},"cell_type":"markdown","source":["Обозначим, что здесь признаки, а что - классы:"]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185},"colab_type":"code","id":"zwVu_NsCZcb2","outputId":"264561a6-089d-4256-bd5c-5aaa12ab769d","executionInfo":{"status":"error","timestamp":1539422639700,"user_tz":-300,"elapsed":670,"user":{"displayName":"Григорий Лелейтнер","photoUrl":"","userId":"07179937308049589303"}}},"cell_type":"code","source":["X = data.iloc[:,:2].values  # матрица объекты-признаки\n","y = data['target'].values.reshape((-1, 1))  # классы (столбец из нулей и единиц)"],"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-70bfe2d34c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m  \u001b[0;31m# матрица объекты-признаки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# классы (столбец из нулей и единиц)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"metadata":{"colab_type":"text","id":"JsuH5PUrZcb5"},"cell_type":"markdown","source":["**Вывод функции потерь**  \n","Функция потерь должна убывать и в итоге стать близкой к 0"]},{"metadata":{"colab":{},"colab_type":"code","id":"PBJ0ZH6SZcb6"},"cell_type":"code","source":["%%time\n","neuron = Neuron()\n","J_values = neuron.fit(X, y)\n","\n","plt.figure(figsize=(10, 8))\n","plt.plot(J_values)\n","plt.title('Функция потерь', fontsize=15)\n","plt.xlabel('номер итерации', fontsize=14)\n","plt.ylabel('$J(\\hat{y}, y)$', fontsize=14)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"X1PcnRTaZcb9"},"cell_type":"markdown","source":["Посмотрим, как теперь нейрон классифицировал объекты из выборки:"]},{"metadata":{"colab":{},"colab_type":"code","id":"7bvaljbsZcb-"},"cell_type":"code","source":["plt.figure(figsize=(10, 8))\n","plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=np.array(neuron.forward_pass(X) > 0.5), cmap='spring')\n","plt.title('Яблоки и груши', fontsize=15)\n","plt.xlabel('симметричность', fontsize=14)\n","plt.ylabel('желтизна', fontsize=14)\n","plt.show();"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"ELtGlYqBZccE"},"cell_type":"markdown","source":["Видим две вещи:  \n","\n","1). С LogLoss работает лучше, чем с квадратичной функцией потерь (MSE);  \n","2). Даже при 5000 итераций качество не самое идеальное.\n","\n","Второй пункт наталкивает на мысль использовать вместо сигмоиды **ReLU** или **Tanh**."]}]}