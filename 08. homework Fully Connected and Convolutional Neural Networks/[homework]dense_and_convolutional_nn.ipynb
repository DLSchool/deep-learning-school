{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[homework]dense_and_convolutional_nn.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KBeojQNTzwY-"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500 height=450/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n","\n","<h3 style=\"text-align: center;\"><b>Домашнее задание. Полносвязные и свёрточные нейронные сети</b></h3>\n","\n","В этом занятии вам предстоит потренироваться построению нейронных сетей с помощью библиотеки Pytorch. Делать мы это будем на нескольких датасетах.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Kd-KUTc1CBXm"},"source":["import numpy as np\n","\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","from sklearn.datasets import make_moons\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","sns.set(style=\"darkgrid\", font_scale=1.4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvKrWYan4Rxr"},"source":["# Часть 1. Датасет moons\n","\n","Давайте сгенерируем датасет и посмотрим на него!"]},{"cell_type":"code","metadata":{"id":"lo3nwjSJFUP7"},"source":["X, y = make_moons(n_samples=10000, random_state=42, noise=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xa9UCvRyJFqL"},"source":["plt.figure(figsize=(16, 10))\n","plt.title(\"Dataset\")\n","plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6BcB14d4wGm"},"source":["Сделаем train/test split"]},{"cell_type":"code","metadata":{"id":"fv5MyTiCHjRh"},"source":["X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iTeLXQg240cQ"},"source":["### Загрузка данных\n","В PyTorch загрузка данных как правило происходит налету (иногда датасеты не помещаются в оперативную память). Для этого используются две сущности `Dataset` и `DataLoader`.\n","\n","1.   `Dataset` загружает каждый объект по отдельности.\n","\n","2.   `DataLoader` группирует объекты из `Dataset` в батчи.\n","\n","Так как наш датасет достаточно маленький мы будем использовать `TensorDataset`. Все, что нам нужно, это перевести из массива numpy в тензор с типом `torch.float32`.\n","\n","### Задание. Создайте тензоры с обучающими и тестовыми данными"]},{"cell_type":"code","metadata":{"id":"msj3bXOeIcN-"},"source":["X_train_t =  # YOUR CODE GOES HERE\n","y_train_t =  # YOUR CODE GOES HERE\n","X_val_t =  # YOUR CODE GOES HERE\n","y_val_t =  # YOUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gqwGMsE_7WBy"},"source":["Создаем `Dataset` и `DataLoader`. "]},{"cell_type":"code","metadata":{"id":"ERvubjbMIu2J"},"source":["train_dataset = TensorDataset(X_train_t, y_train_t)\n","val_dataset = TensorDataset(X_val_t, y_val_t)\n","train_dataloader = DataLoader(train_dataset, batch_size=128)\n","val_dataloader = DataLoader(val_dataset, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BT6eRdVNCO42"},"source":["## Logistic regression is my profession\n","\n","**Напоминание**\n","Давайте вспоним, что происходит в логистической регрессии. На входе у нас есть матрица объект-признак X и столбец-вектор $y$ – метки из $\\{0, 1\\}$ для каждого объекта. Мы хотим найти такую матрицу весов $W$ и смещение $b$ (bias), что наша модель $XW + b$ будет каким-то образом предсказывать класс объекта. Как видно на выходе наша модель может выдавать число в интервале от $(-\\infty;\\infty)$. Этот выход как правило называют \"логитами\" (logits). Нам необходимо перевести его на интервал от $[0;1]$ для того, чтобы он выдавал нам вероятность принадлежности объекта к кассу один, также лучше, чтобы эта функция была монотонной, быстро считалась, имела производную и на $-\\infty$ имела значение $0$, а на $+\\infty$ имела значение $1$. Такой класс функций называется сигмоидыю. Чаще всего в качестве сигмоида берут \n","$$\n","\\sigma(x) = \\frac{1}{1 + e^{-x}}.\n","$$"]},{"cell_type":"markdown","metadata":{"id":"BKyYQcec7cu4"},"source":["### Задание. Реализация логистической регрессии\n","\n","Вам необходимо написать модуль на PyTorch реализующий $logits = XW + b$, где $W$ и $b$ – параметры (`nn.Parameter`) модели. Иначе говоря, здесь мы реализуем своими руками модуль `nn.Linear` (в этом пункте его использование запрещено). Инициализируйте веса нормальным распределением (`torch.randn`)."]},{"cell_type":"code","metadata":{"id":"5U1y-0KtCTne"},"source":["class LinearRegression(nn.Module):\n","    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn)\n","        self.bias = bias\n","        if bias:\n","            self.bias_term = # YOUR CODE GOES HERE\n","\n","    def forward(self, x):\n","        x =  # YOUR CODE GOES HERE\n","        if self.bias:\n","            x +=  # YOUR CODE GOES HERE\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgIgTLHSM-10"},"source":["linear_regression = LinearRegression(2, 1)\n","loss_function = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.SGD(linear_regression.parameters(), lr=0.05)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-VCVmee16yOl"},"source":["**Вопрос 1.** Сколько обучаемых параметров у получившейся модели?"]},{"cell_type":"code","metadata":{"id":"YbTwo8Zt62Y5"},"source":["#YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NV-JrNCoP8E"},"source":["### Train loop\n","\n","Вот псевдокод, который поможет вам разобраться в том, что происходит во время обучения\n","\n","```python\n","for epoch in range(max_epochs):  # <----------- итерируемся по датасету несколько раз\n","    for x_batch, y_batch in dataset:  # <------ итерируемся по датасету. Так как мы используем SGD а не GD, то берем батчи заданного размера\n","        optimizer.zero_grad()  # <------------- обуляем градиенты модели\n","        outp = model(x_batch)  # <------------- получаем \"логиты\" из модели\n","        loss = loss_func(outp, y_batch)  # <--- считаем \"лосс\" для логистической регрессии\n","        loss.backward()  # <------------------- считаем градиенты\n","        optimizer.step()  # <------------------ делаем шаг градиентного спуска\n","        if convergence:  # <------------------- в случае сходимости выходим из цикла\n","            break\n","```\n","\n","В коде ниже добавлено логирование `accuracy` и `loss`."]},{"cell_type":"markdown","metadata":{"id":"U1DvfCPY7TMZ"},"source":["### Задание. Реализация цикла обучения"]},{"cell_type":"code","metadata":{"id":"gVhlIfK0L93s"},"source":["tol = 1e-3\n","losses = []\n","max_epochs = 100\n","prev_weights = torch.zeros_like(linear_regression.weights)\n","stop_it = False\n","for epoch in range(max_epochs):\n","    for it, (X_batch, y_batch) in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        outp =  # YOUR CODE. Use linear_regression to get outputs\n","        loss =  # YOUR CODE. Compute loss\n","        loss.backward()\n","        losses.append(loss.detach().flatten()[0])\n","        optimizer.step()\n","        probabilities =  # YOUR CODE. Compute probabilities\n","        preds = (probabilities > 0.5).type(torch.long)\n","        batch_acc = (preds.flatten() == y_batch).type(torch.float32).sum() / y_batch.size(0)\n","        \n","        if (it + epoch * len(train_dataloader)) % 100 == 0:\n","            print(f\"Iteration: {it + epoch * len(train_dataloader)}\\nBatch accuracy: {batch_acc}\")\n","        current_weights = linear_regression.weights.detach().clone()\n","        if (prev_weights - current_weights).abs().max() < tol:\n","            print(f\"\\nIteration: {it + epoch * len(train_dataloader)}.Convergence. Stopping iterations.\")\n","            stop_it = True\n","            break\n","        prev_weights = current_weights\n","    if stop_it:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBJ64-MT63_r"},"source":["**Вопрос 2.** Сколько итераций потребовалось, чтобы алгоритм сошелся?\n","\n","**Ответ:**"]},{"cell_type":"markdown","metadata":{"id":"As-pgFbzFmiI"},"source":["### Визуализируем результаты"]},{"cell_type":"code","metadata":{"id":"HzPRB8j4b1IF"},"source":["plt.figure(figsize=(12, 8))\n","plt.plot(range(len(losses)), losses)\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cGgcBMNX2WP"},"source":["import numpy as np\n","\n","sns.set(style=\"white\")\n","\n","xx, yy = np.mgrid[-1.5:2.5:.01, -1.:1.5:.01]\n","grid = np.c_[xx.ravel(), yy.ravel()]\n","batch = torch.from_numpy(grid).type(torch.float32)\n","with torch.no_grad():\n","    probs = torch.sigmoid(linear_regression(batch).reshape(xx.shape))\n","    probs = probs.numpy().reshape(xx.shape)\n","\n","f, ax = plt.subplots(figsize=(16, 10))\n","ax.set_title(\"Decision boundary\", fontsize=14)\n","contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n","                      vmin=0, vmax=1)\n","ax_c = f.colorbar(contour)\n","ax_c.set_label(\"$P(y = 1)$\")\n","ax_c.set_ticks([0, .25, .5, .75, 1])\n","\n","ax.scatter(X[100:,0], X[100:, 1], c=y[100:], s=50,\n","           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n","           edgecolor=\"white\", linewidth=1)\n","\n","ax.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9G-UkrE-Arr"},"source":["### Задание. Реализуйте predict и посчитайте accuracy на test."]},{"cell_type":"code","metadata":{"id":"FP_imFpe7Ac4"},"source":["@torch.no_grad()\n","def predict(dataloader, model):\n","    model.eval()\n","    predictions = np.array([])\n","    for x_batch, _ in dataloader:\n","        <YOUR CODE>\n","        preds = #YOUR CODE. Compute predictions\n","        predictions = np.hstack((predictions, preds.numpy().flatten()))\n","    return predictions.flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0vaJdAS7Dfq"},"source":["from sklearn.metrics import accuracy_score\n","\n","# YOUR CODE. Compute total accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7TXs3kk7Kmq"},"source":["**Вопрос 3**\n","\n","Какое `accuracy` получается после обучения?\n","\n","**Ответ:** "]},{"cell_type":"markdown","metadata":{"id":"cyivMZBZC0Ha"},"source":["# Часть 2. Датасет MNIST\n","Датасет MNIST содержит рукописные цифры. Загрузим датасет и создадим DataLoader-ы. Пример можно найти в семинаре по полносвязным нейронным сетям."]},{"cell_type":"code","metadata":{"id":"LuUE2wihC4GW"},"source":["import os\n","from torchvision.datasets import MNIST\n","\n","data_tfs = tfs.Compose([\n","    tfs.ToTensor(),\n","    tfs.Normalize((0.5), (0.5))\n","])\n","\n","# install for train and test\n","root = './'\n","train_dataset = MNIST(root, train=True,  transform=data_tfs, download=True)\n","val_dataset  = MNIST(root, train=False, transform=data_tfs, download=True)\n","\n","train_dataloader =  # YOUR CODE GOES HERE\n","valid_dataloader =  # YOUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4t2w2XtSB1Hd"},"source":["## Часть 2.1. Полносвязные нейронные сети\n","Сначала решим MNIST с помощью полносвязной нейронной сети."]},{"cell_type":"code","metadata":{"id":"Zvcy_wYFh1Lv"},"source":["class Identical(nn.Module):\n","    def forward(self, x):\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HMtCBdCA-4bj"},"source":["### Задание. Простая полносвязная нейронная сеть \n","\n","Создайте полносвязную нейронную сеть с помощью класса Sequential. Сеть состоит из:\n","* Уплощения матрицы в вектор (nn.Flatten);\n","* Двух скрытых слоёв из 128 нейронов с активацией nn.ELU;\n","* Выходного слоя с 10 нейронами.\n","\n","Задайте лосс для обучения (кросс-энтропия).\n"]},{"cell_type":"code","metadata":{"id":"ulxWHddEiQCr"},"source":["activation = nn.ELU\n","\n","model = nn.Sequential(\n","    nn.Flatten(),\n","    #YOUR CODE. Add layers to your sequential class\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIl6z-AfivcK"},"source":["criterion = #YOUR CODE. Select a loss function\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whvqhLjYmpKc"},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Xl_HawRGRAe"},"source":["### Train loop (seriously)\n","\n","Давайте разберемся с кодом ниже, который подойдет для 90% задач в будущем.\n","\n","\n","```python\n","for epoch in range(max_epochs):  # <--------------- итерируемся по датасету несколько раз\n","    for k, dataloader in loaders.items():  # <----- несколько dataloader для train / valid / test\n","        for x_batch, y_batch in dataloader:  # <--- итерируемся по датасету. Так как мы используем SGD а не GD, то берем батчи заданного размера\n","            if k == \"train\":\n","                model.train()  # <------------------ переводим модель в режим train\n","                optimizer.zero_grad()  # <--------- обнуляем градиенты модели\n","                outp = model(x_batch)\n","                loss = criterion(outp, y_batch) # <-считаем \"лосс\" для логистической регрессии\n","                loss.backward()  # <--------------- считаем градиенты\n","                optimizer.step()  # <-------------- делаем шаг градиентного спуска\n","            else:  # <----------------------------- test/eval\n","                model.eval()  # <------------------ переводим модель в режим eval\n","                with torch.no_grad():  # <--------- НЕ считаем градиенты\n","                    outp = model(x_batch)  # <------------- получаем \"логиты\" из модели\n","            count_metrics(outp, y_batch)  # <-------------- считаем метрики\n","```"]},{"cell_type":"markdown","metadata":{"id":"raKQWwQm_9Ff"},"source":["### Задание. Дополните цикл обучения."]},{"cell_type":"code","metadata":{"id":"3Tmo1lsHjBE6"},"source":["max_epochs = 10\n","accuracy = {\"train\": [], \"valid\": []}\n","for epoch in range(max_epochs):\n","    for k, dataloader in loaders.items():\n","        epoch_correct = 0\n","        epoch_all = 0\n","        for x_batch, y_batch in dataloader:\n","            if k == \"train\":\n","                 # YOUR CODE. Set model to ``train`` mode and calculate outputs. Don't forget zero_grad!\n","            else:\n","                 # YOUR CODE. Set model to ``eval`` mode and calculate outputs\n","            preds = outp.argmax(-1)\n","            correct =  # YOUR CODE GOES HERE\n","            all =  # YOUR CODE GOES HERE\n","            epoch_correct += correct.item()\n","            epoch_all += all\n","            if k == \"train\":\n","                loss = criterion(outp, y_batch)\n","                # YOUR CODE. Calculate gradients and make a step of your optimizer\n","        if k == \"train\":\n","            print(f\"Epoch: {epoch+1}\")\n","        print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n","        accuracy[k].append(epoch_correct/epoch_all)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fFRxO1-FK9U9"},"source":["### Задание. Протестируйте разные функции активации.\n","Попробуйте разные функции активации. Для каждой функции активации посчитайте массив validation accuracy. Лучше реализовать это в виде функции, берущей на вход активацию и получающей массив из accuracies."]},{"cell_type":"code","metadata":{"id":"SezseDhEqhm2"},"source":["elu_accuracy = accuracy[\"valid\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSVBlHtuAUAh"},"source":["# YOUR CODE. Do the same thing with other activations (it's better to wrap into a function that returns a list of accuracies)\n","\n","def test_activation_function(activation):\n","    #YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1iXow0Tqsri"},"source":["plain_accuracy = test_activation_function(Identical)\n","relu_accuracy = #YOUR CODE\n","leaky_relu_accuracy = #YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FK07mms3FwNd"},"source":["### Accuracy\n","Построим график accuracy/epoch для каждой функции активации."]},{"cell_type":"code","metadata":{"id":"cvKclpM5r-P3"},"source":["sns.set(style=\"darkgrid\", font_scale=1.4)\n","\n","plt.figure(figsize=(16, 10))\n","plt.title(\"Valid accuracy\")\n","plt.plot(range(max_epochs), plain_accuracy, label=\"No activation\", linewidth=2)\n","plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4R8L1JCts_qz"},"source":["plt.figure(figsize=(16, 10))\n","plt.title(\"Valid accuracy\")\n","plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bl8qYSSa7c-r"},"source":["**Вопрос 4.** Какая из активаций показала наивысший `accuracy` к концу обучения?\n","\n","**Ответ:**"]},{"cell_type":"markdown","metadata":{"id":"ebq7icV8CbrU"},"source":["## Часть 2.2 Сверточные нейронные сети"]},{"cell_type":"markdown","metadata":{"id":"9bXylTAuCqu-"},"source":["### Ядра\n","Сначала немного поработам с самим понятием ядра свёртки."]},{"cell_type":"code","metadata":{"id":"G7P75exc0acy"},"source":["!wget https://img.the-village.kz/the-village.com.kz/post-cover/5x5-I6oiwjmq79dMCZMEbA-default.jpg -O sample_photo.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88YOXq0CCyUM"},"source":["import cv2\n","sns.set(style=\"white\")\n","img = cv2.imread(\"sample_photo.jpg\")\n","RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(12, 8))\n","plt.imshow(RGB_img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iu9oxwbL-6xE"},"source":["Попробуйте посмотреть как различные свертки влияют на фото. Например, попробуйте \n","A)\n","```\n","[0, 0, 0],\n","[0, 1, 0],\n","[0, 0, 0]\n","```\n","Б)\n","```\n","[0, 1, 0],\n","[0, -2, 0],\n","[0, 1, 0]\n","```\n","В)\n","```\n","[0, 0, 0],\n","[1, -2, 1],\n","[0, 0, 0]\n","```\n","Г)\n","```\n","[0, 1, 0],\n","[1, -4, 1],\n","[0, 1, 0]\n","```\n","Д)\n","```\n","[0, -1, 0],\n","[-1, 5, -1],\n","[0, -1, 0]\n","```\n","Е)\n","```\n","[0.0625, 0.125, 0.0625],\n","[0.125, 0.25, 0.125],\n","[0.0625, 0.125, 0.0625]\n","```\n","\n","Не стесняйтесь пробовать свои варианты!"]},{"cell_type":"code","metadata":{"id":"-0WNZro01pZE"},"source":["img_t = torch.from_numpy(RGB_img).type(torch.float32).unsqueeze(0)\n","kernel = torch.tensor([\n","    [0, 0, 0],\n","    [1, -2, 1],\n","    [0, 0, 0]\n","]).reshape(1, 1, 3, 3).type(torch.float32)\n","\n","kernel = kernel.repeat(3, 3, 1, 1)\n","img_t = img_t.permute(0, 3, 1, 2)  # [BS, H, W, C] -> [BS, C, H, W]\n","img_t = nn.ReflectionPad2d(1)(img_t)  # Pad Image for same output size\n","\n","result = F.conv2d(img_t, kernel)[0]  #"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-SAfc7x28ko"},"source":["plt.figure(figsize=(12, 8))\n","result_np = result.permute(1, 2, 0).numpy() / 256 / 3\n","\n","plt.imshow(result_np)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDapwqTXGC4e"},"source":["**Вопрос 5.** Как можно описать действия ядер, приведенных выше? Сопоставьте для каждой буквы число.\n","\n","1) Размытие\n","\n","2) Увеличение резкости\n","\n","3) Тождественное преобразование\n","\n","4) Выделение вертикальных границ\n","\n","5) Выделение горизонтальных границ\n","\n","6) Выделение границ\n","\n","**Ответ:**"]},{"cell_type":"markdown","metadata":{"id":"4b9ib9saC9Vb"},"source":["### Задание. Реализуйте LeNet\n","\n","Если мы сделаем параметры сверток обучаемыми, то можем добиться хороших результатов для задач компьютерного зрения. Реализуйте архитектуру LeNet, предложенную еще в 1998 году!\n","На этот раз используйте модульную структуру (без помощи класса Sequential). \n","\n","Наша нейронная сеть будет состоять из\n","* Свёртки 3x3 (1 карта на входе, 6 на выходе) с активацией ReLU;\n","* MaxPooling-а 2x2;\n","* Свёртки 3x3 (6 карт на входе, 16 на выходе) с активацией ReLU;\n","* MaxPooling-а 2x2;\n","* Уплощения (nn.Flatten);\n","* Полносвязного слоя со 120 нейронами и активацией ReLU;\n","* Полносвязного слоя с 84 нейронами и активацией ReLU;\n","* Выходного слоя из 10 нейронов.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"lE8qJByKC-u0"},"source":["class LeNet(nn.Module):\n","    def __init__(self):\n","        super(LeNet, self).__init__()\n","        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n","        self.conv1 = nn.Conv2d(1, 6, 3)\n","        self.pool1 = #YOUR CODE\n","        self.conv2 = #YOUR CODE\n","        self.pool2 = #YOUR CODE\n","        self.fc1 = #YOUR CODE  \n","        self.fc2 = #YOUR CODE\n","        self.fc3 = #YOUR CODE\n","\n","    def forward(self, x):\n","        x = #YOUR CODE. Apply layers created in __init__. \n","        ...\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dgfBX_HPyd_z"},"source":["model = LeNet().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J21MIKtjRNWA"},"source":["### Задание. Обучите CNN\n","Используйте код обучения, который вы написали для полносвязной нейронной сети."]},{"cell_type":"code","metadata":{"id":"X06XkVKiFQLi"},"source":["<YOUR CODE>"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uFT5XKS1ytA2"},"source":["lenet_accuracy = accuracy[\"valid\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-PwAI5SPMBx"},"source":["Сравним с предыдущем пунктом"]},{"cell_type":"code","metadata":{"id":"VDq6pSi_yytp"},"source":["plt.figure(figsize=(16, 10))\n","plt.title(\"Valid accuracy\")\n","plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n","plt.plot(range(max_epochs), lenet_accuracy, label=\"LeNet\", linewidth=2)\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3NCpTE3726m"},"source":["**Вопрос 6**\n","Какое `accuracy` получается после обучения с точностью до двух знаков после запятой?\n","\n","**Ответ:**"]}]}