{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[homework]LanguageModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gRoNMvaC4uKK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vr4atkrm_QF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(random_seed)\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "# Включите куду\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMOZs2ij4uKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Погружение в Natural Language Proccessing\n",
        "\n",
        "Так как обработкой языка занимались давно, а нейронные сети пытаются вставить везде лишь лет 10, то прежде чем решать задачи с помощью NN хотелось бы попробовать решить ее классическими методами. \n",
        "\n",
        "\n",
        "В данном задании мы будем всеми силами пытаться построить языковую модель (language model). \n",
        "\n",
        "Что же такое языковая модель? (если вдруг кто-то забыл после лекции)\n",
        "\n",
        "Сейчас прольем немного математики, а ниже опишем обычными словами все это.\n",
        "\n",
        "Допустим, у нас есть огромный текстовый корпус содержащий какой-либо смысл и нам хотелось бы уметь создавать такой текст с помощью обученной модели. Для этого нам необходимо знать вероятность $p(W) = p(w_1, w_2, w_3,..) $ появления предложения или последовательности слов или же нам интересно получить вероятность $p(w_5| w_1, w_2, w_3, w_4)$ появления слова при контексте. Будем называть модели, которые считают такие вероятности языковыми моделями.\n",
        "\n",
        "#### Что это за модель? \n",
        "\n",
        "Тут везде почему-то говорится про какую-то неведомую модель. Уточню, вообще говоря, модель (в статистическом смысле, конечно) является математическим представлением процесса. Почти всегда модели являются приближением процесса. Для этого есть несколько причин, но два наиболее важных:\n",
        "1. Обычно мы наблюдаем только процесс ограниченное количество раз\n",
        "2. Модель может быть исключительно сложной, поэтому мы ее упрощаем\n",
        "\n",
        "Вот что обычно делает модель: она описывает, как моделируемый процесс __создает данные__. В нашем случае моделируемым явлением является человеческий язык. Языковая модель дает нам способ генерации человеческого языка. Эти модели обычно составлены из вероятностных распределений.\n",
        "\n",
        "Модель построена путем наблюдения некоторых образцов, сгенерированных явлением, которое должно быть смоделировано. Таким же образом, языковая модель строится путем наблюдения за некоторым текстом.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "k4fQPdp34uKN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bag Of Words (мешок слов) \n",
        "\n",
        "Так как мы решили немного проникнуться nlp, стоит обязательно познать абстракцию мешка слов.  Вообще эта идея, есть наиболее простой способ сопоставления слова-вектор( ведь компьютер у нас может работать только с цифрами, поэтому надо каким-то образом уметь превращать буквы/слова в них) Это, безусловно, самый простой способ моделирования человеческого языка. Это не значит, что это бесполезно и непопулярно.\n",
        "\n",
        "Идея очень проста: посчитаем частоту встречания слов в словаре и составим из этого один вектор.\n",
        "\n",
        "![img](https://hsto.org/getpro/habr/post_images/b91/46a/5be/b9146a5be315f422479e40d85e995289.jpg)\n",
        "\n",
        "Попробуем закодить для настоящего корпуса собраний сочинений Федора Михайловича Достоевского"
      ]
    },
    {
      "metadata": {
        "id": "f_V0UqK-6UJy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/DLSchool/dlschool_old/master/materials/homeworks/hw09/dostoevsky.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0o5du4f4uKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "with io.open('dostoevsky.txt', 'r',encoding='utf8') as f:\n",
        "    text = f.read().replace(u'\\xa0', u' ').replace(u'\\ufeff','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gCrqQz-4uKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDsn5wIK4uKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(words), len(sents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0K9gpI6-q5e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Вопрос 1: Сколько слов и предложений в датасете?\n",
        "\n",
        "hint: используйте  word_tokenize & sent_tokenize из nltk"
      ]
    },
    {
      "metadata": {
        "id": "HDLvolAj4uKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize\n",
        "\n",
        "sents_full = sent_tokenize(text)\n",
        "sents = [word_tokenize(s) for s in sents_full]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNXv4hMa4uKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import reuters\n",
        "from collections import Counter\n",
        " \n",
        "counts = Counter(words)\n",
        "total_count = len(words)\n",
        "\n",
        "# Напечатайте 20 наиболее популярных слов hint: use counter methods\n",
        " \n",
        "# Посчитайте их частоту встречания hint: you know total count\n",
        "\n",
        "# Внимание: частота в данном контексте является вероятностью появления слова (независимой)\n",
        "# Поэтому проверьте основное свойство - суммирование  в 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bYgFTrzApYU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Вопрос 2**\n",
        "\n",
        "Каковы частоты для слов \n",
        "\"бесы\", '\"семья\", \"брат\"'. Введите значение округленное до 5 знаков с помощью функции round"
      ]
    },
    {
      "metadata": {
        "id": "s5pXCTmR4uKX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        " \n",
        "# Код для генерации текста уже имеющейся моделью\n",
        "new_text = []\n",
        " \n",
        "for _ in range(30):\n",
        "    accumulator = .0\n",
        "    r = random.random()\n",
        "    for word, freq in counts.items():\n",
        "        accumulator += freq\n",
        " \n",
        "        if accumulator >= r:\n",
        "            new_text.append(word)\n",
        "            break\n",
        "\n",
        "print(' '.join(new_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJGJ5SyN_689",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Еще один простой вопрос.\n",
        "\n",
        "**Вопрос №3.**\n",
        "Попрубйте сгенерировать текст, который состои из слов с вероятностями . появления от 0. 85 до 0.95  и итоговое предложение состоит из 10 слов."
      ]
    },
    {
      "metadata": {
        "id": "PTT7VoK6_J6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95eb0c74-420a-4168-c6f6-02408987284d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(' '.join(new_text))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "он… замирающим веков правильным всматриваться черепа иеромонахи солжем откупорил победе\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNRpkUBV4uKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Как вы можете видеть, это не самый выразительный фрагмент контента. Полученный текст следует только частотным правилам языка и не более того.\n",
        "\n",
        "\n",
        "#### Биграммы,  триграммы и n-граммы\n",
        "\n",
        "Одна идея, которая может помочь нам создать более качественный текст, состоит в том, чтобы убедиться, что новое слово, которое мы добавляем в последовательность, хорошо сочетается с уже существующими словами. Проверка правильности слова после 10 слов может немного переборщить. Мы можем упростить все, чтобы проблема была разумной. Давайте сделаем так, чтобы новое слово получилось после последнего слова в последовательности (модель биграмм) или двух последних слов (модель триграмм) ( можно так долго продолжат, из эмпирических наблюдений при n=5 модель всегда выдает нормальный текст ) .\n",
        "\n",
        "«Биграм» - это причудливое имя для двух последовательных слов, в то время как триграмма (как вы уже догадались) триплет последовательных слов. Вот некоторые быстрые магии NLTK (библиотека для nlp) для извлечения биграмм / триграмм:"
      ]
    },
    {
      "metadata": {
        "id": "-kC3rxCw4uKd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        " \n",
        "first_sentence = word_tokenize(sents_full[0])\n",
        "print(first_sentence)\n",
        "\n",
        "# Get the bigrams\n",
        "print(list(bigrams(first_sentence)))\n",
        "\n",
        "# Get the padded bigrams\n",
        "print(list(bigrams(first_sentence, pad_left=True, pad_right=True)))\n",
        " \n",
        "# Get the trigrams\n",
        "print(list(trigrams(first_sentence)))\n",
        " \n",
        "# Get the padded trigrams\n",
        "print(list(trigrams(first_sentence, pad_left=True, pad_right=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xb50ohuh4uKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь можно и модель над этими биграммами построить. "
      ]
    },
    {
      "metadata": {
        "id": "yoTmzV-J4uKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        " \n",
        "for sentence in sents:\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        "        \n",
        "# следует теперь привести количество встречаемостей к частотам\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for - in -:\n",
        "        приводим"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUhA9Q3VA8T0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Вопрос 4**\n",
        "Какова вероятность слова $w_3$ при условии $w_1, w_2$\n",
        "выпишите три числа для $w_3 \\in [\\text{вам, слона, коридорчику}]$\n",
        "\n",
        "А соответсвующие им биграммы: {[чтоб еще], [мухи, сочинили], [прямо, по]}\n",
        "\n",
        "Не перепутайтн порядок."
      ]
    },
    {
      "metadata": {
        "id": "d7oYbFy44uKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Можете поискать еще интересных сочитаний в модели. Например найти самое часто встречаемое в тексте выражение. Или попробовать использовать пятиграммную модель. Это довольно интересно. \n",
        "\n",
        "Ниже, наконец представлен код для нашей генеративной модели. Рекомендую с ним так же поиграться."
      ]
    },
    {
      "metadata": {
        "id": "qDu_CEdc4uKq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_text = [None, None]\n",
        " \n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        "    for word in model[tuple(new_text[-2:])].keys():\n",
        "        accumulator += model[tuple(new_text[-2:])][word]\n",
        "        if accumulator >= r:\n",
        "            new_text.append(word)\n",
        "            break\n",
        " \n",
        "    if new_text[-2:] == [None, None]:\n",
        "        sentence_finished = True\n",
        "\n",
        "print(' '.join([t for t in new_text if t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1oUkT7L0DdYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = 'Я тогда это говорил'\n",
        "\n",
        "new_text = word_tokenize(start)\n",
        " \n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        "    for word in model[tuple(new_text[-2:])].keys():\n",
        "        accumulator += model[tuple(new_text[-2:])][word]\n",
        "        if accumulator >= r:\n",
        "            new_text.append(word)\n",
        "            break\n",
        " \n",
        "    if new_text[-2:] == [None, None]:\n",
        "        sentence_finished = True\n",
        "\n",
        "print(' '.join([t for t in new_text if t]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTOGAGFeBMuf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Вопрос 5**\n",
        "\n",
        "Сгенерируйте предложение в ячейке выше 10 раз и введите символ, который наиболее часто появлялся в вашем итоговом предложении."
      ]
    },
    {
      "metadata": {
        "id": "a7aT5DWVBcQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ans_characters"
      ]
    },
    {
      "metadata": {
        "id": "cdAL-jmJ4uKs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "На данном этапе моедль уже может генерировать более осмысленный текст. Кроме того существует множество статистических методом, которые могают сгладить распределение слов, бороться с появление новых n-грамм. И такие модели до сих пор могут спокойно соревноваться с нейронными решениями. \n",
        "\n",
        "Собственно покатили в нейронный мир."
      ]
    },
    {
      "metadata": {
        "id": "zVfOD0lw4uKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## char-RNN in PyTorch\n",
        "\n",
        "Тут нам предстоит построить character-level RNN c помощью PyTroch. Для того чтобы освежить свои знания о данной модели рекомендую к прочтению [сию статью](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) написанную Андреем Карпатым.  Сразу проясню, тут мы будем "
      ]
    },
    {
      "metadata": {
        "id": "soNaU_x24uKt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import io\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AuC_LhMY4uKv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Обновите текст, если что-то потерлось. Можно сделать это не только в памяти компьютера, но и в своей собственной."
      ]
    },
    {
      "metadata": {
        "id": "RkuXhwlj4uKw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with io.open('dostoevsky.txt', 'r',encoding='utf8') as f:\n",
        "    text = f.read().replace(u'\\xa0', u' ').replace(u'\\ufeff','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQ03nFMv4uKy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text[:300]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pK4m1Sl54uK3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Закодируем наш текст в цифры, как мы и обсуждали ранее."
      ]
    },
    {
      "metadata": {
        "id": "9W7N9Vwv4uK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = tuple(set(text))\n",
        "int2char = dict(enumerate(chars))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "encoded = np.array([char2int[ch] for ch in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ua3-2ZuN4uK7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded.shape # Наш словарь получился очень большой"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsNhlzn34uK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Обработка данных\n",
        "\n",
        "Будем использовать для представления букв one-hot вектора. Напишите функцию для этого."
      ]
    },
    {
      "metadata": {
        "id": "Jf5GQulo4uK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    \n",
        "    # Инициализируем вектора \n",
        "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
        "    \n",
        "    # заполним 1 в соответсвующем месте\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        "    # Приводим к нужному размеру\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SLmKXB494uLA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Попробуйте сделать функцию ниже, которая строит генератор мини-батчей. Каждая последовательность будет длины `n_steps`"
      ]
    },
    {
      "metadata": {
        "id": "XWR0XuI14uLA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batches(arr, n_seqs, n_steps):\n",
        "    \"\"\"\n",
        "    Создание генератора, возвращающего минибатчи размера (n_seqs x seq_len) Numpy\n",
        "    \"\"\"    \n",
        "    batch_size = n_seqs * n_steps\n",
        "    n_batches = len(arr)//batch_size\n",
        "    \n",
        "    # Keep only enough characters to make full batches\n",
        "    arr = arr[:n_batches * batch_size]\n",
        "    # Reshape into n_seqs rows\n",
        "    arr = arr.reshape((n_seqs, -1))\n",
        "    \n",
        "    for n in range(0, arr.shape[1], n_steps):\n",
        "        # The features\n",
        "        x = arr[:, n:n+n_steps]\n",
        "        # The targets, shifted by one\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_steps]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zc1bkSne4uLC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Построение charRNN модели\n",
        "\n",
        "Ниже вам будет необходимо написать свою char-rnn по данному описанию. Как всегда основные рекомендации: сначала пишем определение слоев в  init, затем описываем их вызов в forward.\n",
        "\n",
        "\n",
        "Кроме того тут есть важная функция predict. (в блоге Карпатого очень подробно все описано и дабы не заниматься копипастой, я направляю вас туда). Для начала попробуйте проверить учится ли ваша сеть и только потом заполняйте метод predict.\n",
        "\n",
        "Почему даем именно модель над символами? Потому что это очень простая структура, которая может быть применена не только к текстам, но и к музыке. "
      ]
    },
    {
      "metadata": {
        "id": "38Qqu4TbMBit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, tokens, n_steps=100, n_hidden=256, n_layers=2,\n",
        "                               drop_prob=0.1, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "        \n",
        "        self.dropout = <dropout>\n",
        "        self.lstm = <torch gru will be the best choice>\n",
        "        self.fc = <linear>\n",
        "        \n",
        "        self.init_weights()\n",
        "        \n",
        "    def forward(self, x, hc):\n",
        "        ''' Forward pass through the network '''\n",
        "        x, h = self.lstm(x, hc)\n",
        "#         x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x, h\n",
        "    \n",
        "    def predict(self, char, h=None, top_k=None):\n",
        "        \"\"\"        \n",
        "            Returns the predicted character and the hidden state.\n",
        "        \"\"\"\n",
        "        \n",
        "        if h is None:\n",
        "            h = self.init_hidden(1).to(device)\n",
        "        \n",
        "        x = np.array([[self.char2int[char]]])\n",
        "        x = <one-hot>\n",
        "        \n",
        "        inputs = torch.from_numpy(x).to(device)\n",
        "        out, h = self.forward(inputs, h)\n",
        "\n",
        "        p = <Get proba vector (softmax on last dimension)>\n",
        "        \n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(self.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        p = p.numpy().squeeze()\n",
        "        # Choose 1/k \n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        return self.int2char[char], h\n",
        "    \n",
        "    def init_weights(self):\n",
        "        ''' Initialize weights for fully connected layer '''        \n",
        "        # Set bias tensor to all zeros\n",
        "        self.fc.bias.data.fill_(0)\n",
        "        # FC weights as random uniform\n",
        "        self.fc.weight.data.uniform_(-1, 1)\n",
        "        \n",
        "    def init_hidden(self, n_seqs):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, n_seqs, self.n_hidden).zero_()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "46Q9uU754uLE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Для проверки функционирования у нас есть функция `train` , которая позволит провести вам большое число экспериментов."
      ]
    },
    {
      "metadata": {
        "id": "C99mWJAT4uLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(net, data, epochs=10, n_seqs=10, n_steps=50, lr=0.0005, clip=3, val_frac=0.1, cuda=False, print_every=200):\n",
        "    net.train()\n",
        "#     opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    opt = <Optimizer : Adam is the best choice>\n",
        "    criterion = <CE> \n",
        "    \n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        h = net.init_hidden(n_seqs)\n",
        "        for x, y in get_batches(data, n_seqs, n_steps):\n",
        "            counter += 1\n",
        "            \n",
        "            # Кодируем данные и отправлячем\n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs = torch.from_numpy(x).to(device)\n",
        "            targets = torch.from_numpy(y).to(device)\n",
        "            \n",
        "            #  замените на .copy будет работать стабильнее\n",
        "            h = torch.tensor(h.data, device=device)\n",
        "\n",
        "            net.zero_grad()\n",
        "            \n",
        "            output, h = net.forward(inputs, h)\n",
        "            \n",
        "            loss = criterion(output.view(n_seqs*n_steps,-1), targets.view(n_seqs*n_steps))\n",
        "            loss.backward()\n",
        "            \n",
        "            # clip grad norm может вам помочь\n",
        "            nn.utils.clip_grad_norm_(<TODO>)\n",
        "\n",
        "            opt.step()\n",
        "            \n",
        "            if counter % print_every == 0:\n",
        "                net.eval()\n",
        "                # Get validation loss\n",
        "                val_h = net.init_hidden(n_seqs)\n",
        "                val_losses = []\n",
        "                for x, y in get_batches(val_data, n_seqs, n_steps):\n",
        "                    # One-hot encode our data and make them Torch tensors\n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    inputs = torch.from_numpy(x).to(device)\n",
        "                    targets = torch.from_numpy(y).to(device)\n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    val_h = val_h.clone().detach()\n",
        "                    output, val_h = net.forward(inputs, val_h)\n",
        "                    val_loss = criterion(output.view(n_seqs*n_steps,-1), targets.view(n_seqs*n_steps))\n",
        "                    val_losses.append(val_loss.item())\n",
        "                   \n",
        "                # Попробуем валидироваться таким способом\n",
        "                prime = 'Дом'\n",
        "                top_k = 2\n",
        "                chars = [ch for ch in prime]\n",
        "                vh = None\n",
        "                for ch in prime:\n",
        "                    char, vh = net.predict(ch, vh, top_k=top_k)\n",
        "                for ii in range(10):\n",
        "                    char, vh = net.predict(chars[-1], vh, top_k=top_k)\n",
        "                    chars.append(char)\n",
        "                    \n",
        "                chars.append(char)\n",
        "                print(' '.join(chars))\n",
        "                net.train()\n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)),\n",
        "                       \"Validation Perplexity: {:.4f}\".format(np.exp(np.mean(val_losses))))\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pvSblHi44uLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Время тренировки!\n",
        "\n",
        " \n",
        "Теперь мы можем тренировать сеть. Сначала мы создадим саму сеть, с некоторыми заданными гиперпараметрами. Затем определите размеры мини-партий (количество последовательностей и количество шагов) и начните обучение. С функцией поезда мы можем установить количество эпох, скорость обучения и другие параметры. Кроме того, мы можем запустить обучение на графическом процессоре, установив `cuda = True`. Сейчас google дает всем бесплатно использовать gpu с помощью сервиса codelab.\n",
        "\n",
        "\n",
        "![a](https://www.apmpodcasts.org/wp-content/uploads/2015/06/adventure-time.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "hAcQeadQ4uLH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if 'net' in locals():\n",
        "    del net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBBOtwJM4uLJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_hidden_units = <подберите оптимальное значение (помните, что это буквы)>\n",
        "net = CharRNN(chars, n_hidden=num_hidden_units, n_layers=2).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "gjSO9VtL4uLM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_seqs, n_steps = 128, 100\n",
        "print_every = 100\n",
        "train(net, encoded, epochs=15, n_seqs=n_seqs, n_steps=n_steps, lr=0.0005, cuda=True, print_every=print_every)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ff7gRb4F4uLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![train](https://i.pinimg.com/474x/0e/58/69/0e5869297852211e8447d6b09fa1f4f5.jpg)\n",
        "\n",
        "**Вопрос 6**\n",
        "\n",
        "Введите целую часть итоговой  перплексии ex. [142.37 ] = 142"
      ]
    },
    {
      "metadata": {
        "id": "TGHV-y2d4uLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Загрузка модели \n",
        "\n",
        "Чтобы настроить гиперпараметры для получения максимальной производительности, вам понадобятся наблюдения за обучением и валидацией. Если ваша потеря обучения намного ниже, чем потеря проверки, вы перерабатываете. Увеличьте регуляризацию (больше выпадений) или используйте меньшую сеть. Если потери обучения и проверки близки, вы недофинансируете, чтобы увеличить размер сети."
      ]
    },
    {
      "metadata": {
        "id": "76hVSahj4uLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "После обучения мы сохраним модель, чтобы мы могли загрузить ее позже, если понадобится. Здесь сохраняются параметры, необходимые для создания той же архитектуры, гиперпараметров скрытого слоя и текстовых символов."
      ]
    },
    {
      "metadata": {
        "id": "LzWyveW24uLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = {'n_hidden': net.n_hidden,\n",
        "              'n_layers': net.n_layers,\n",
        "              'state_dict': net.state_dict(),\n",
        "              'tokens': net.chars}\n",
        "with open('./rnn.net', 'wb') as f:\n",
        "    torch.save(checkpoint, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmMeiwj_4uLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Семплирование\n",
        "\n",
        "Теперь, когда модель обучена, мы захотим попробовать ее. Чтобы заполучить текст, мы передаем символ и сеть прогнозируем следующий символ. Затем мы берем новый символ, передаем его обратно и получаем еще один. Просто продолжайте делать это, и вы создадите кучу текста!\n",
        "\n",
        "### Top K \n",
        "\n",
        "Наши прогнозы основаны на категориальном распределении вероятностей по всем возможным признакам. Мы можем сделать выборку более разумным, но менее переменным, учитывая только некоторые вероятные символы $ K $. Это будет препятствовать тому, чтобы сеть давала нам абсолютно абсурдные символы, позволяя ей вводить некоторый шум и случайность в выбранный текст.\n",
        "\n",
        "Как правило, вы хотите настроить сеть, чтобы создать скрытое состояние. В противном случае сеть начнет генерировать символы наугад.]"
      ]
    },
    {
      "metadata": {
        "id": "F83uekj74uLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Из основного задания, попробуйте сгенерировать небольшой рассказик. Поиграйте с параметрами. Найдите собственный датасет( чтобы проверяющим было весело ) и попробуйте обучить нейронную сеть на нем. \n",
        "\n",
        "Не забывайте эксперементировать со структурой. У LSTM много аналогий, посмотрите как они справляются с данной задачей и запишите это в отчет. \n",
        "\n",
        "**Вопрос 7**\n",
        "\n",
        "Введите результат модели. Помните, он должен быть осмысленным.\n"
      ]
    },
    {
      "metadata": {
        "id": "9nLlCmPO4uLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(net, size, prime='The', top_k=None, cuda=False):\n",
        "    net.eval()\n",
        "    # First off, run through the prime characters\n",
        "    chars = [ch for ch in prime]\n",
        "    h = None\n",
        "    for ch in prime:\n",
        "        char, h = net.predict(ch, h,top_k=top_k)\n",
        "        \n",
        "    chars.append(char)\n",
        "    \n",
        "    # Now pass in the previous character and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = net.predict(chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u6toyTr04uLX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "print(sample(net, 25, prime='Путин', top_k=2, cuda=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ISqy7dUYFyf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Посмотрим на семлы случайной модели."
      ]
    },
    {
      "metadata": {
        "id": "CE_omhdlFnjs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(sample(CharRNN(chars, n_hidden=num_hidden_units, n_layers=2).to(device), \n",
        "             20, prime='Путин ', top_k=5, cuda=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ep25-RYYJEW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Разница видна, значит мы все сделали правильно."
      ]
    },
    {
      "metadata": {
        "id": "r1XJ-2PT4uLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('./rnn.net', 'rb') as f:\n",
        "    checkpoint = torch.load(f)\n",
        "    \n",
        "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
        "loaded.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZisXBVB4uLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Вопрос 8\n",
        "\n",
        "\n",
        "Тут предлагается описать все проделанные эксперименты. Отчет будет весить 2 балла из 10.  Попробуйте сделать его насыщенным необходимой информацией для проверяющих, чтобы можно было сразу оценить сколько было проделано работы. Пример вопросов для отчета был дан выше. Можно добавить семплы модели на эпохах 1, 3, 9, 15, для лучшего понимания обучения."
      ]
    }
  ]
}