{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[homework]nlp_basics.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["tysPoe5rwC6I"]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"Ot3c4fjZwC4T","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"metadata":{"id":"P2JdzEXmwRU5","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"oMohh_6CwC4W","colab_type":"text"},"cell_type":"markdown","source":["### Задача определения частей речи, Part-Of-Speech Tagger (POS)"]},{"metadata":{"id":"2Aad2tmBwC4Y","colab_type":"text"},"cell_type":"markdown","source":["Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM)."]},{"metadata":{"scrolled":false,"id":"gYYV0mdmwC4f","colab_type":"code","colab":{}},"cell_type":"code","source":["import nltk\n","import pandas as pd\n","import numpy as np\n","from collections import OrderedDict, deque\n","from nltk.corpus import brown\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FPgI52lRwC4n","colab_type":"text"},"cell_type":"markdown","source":["Вам в помощь http://www.nltk.org/book/"]},{"metadata":{"id":"hxdJxMEAwC4o","colab_type":"text"},"cell_type":"markdown","source":["Загрузим brown корпус"]},{"metadata":{"id":"ZvhXAL_9wC4q","colab_type":"code","colab":{}},"cell_type":"code","source":["nltk.download('brown')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wto8PSC6wC4v","colab_type":"text"},"cell_type":"markdown","source":["<b>Существует не одна система тегирования, поэтому будьте внимательны, когда прогнозируете тег слов в тексте и вычисляете качество прогноза. Можете получить несправедливо низкое качество вашего решения."]},{"metadata":{"id":"De6wkE6VwC4w","colab_type":"text"},"cell_type":"markdown","source":["На семинаре была рассмотрена вот эта система."]},{"metadata":{"id":"0ZwtiRXWwC4y","colab_type":"text"},"cell_type":"markdown","source":["![image.png](attachment:image.png)"]},{"metadata":{"id":"eJ6tuHA_wC4z","colab_type":"text"},"cell_type":"markdown","source":["Будем использовать универсальную систему тегирования universal_tagset "]},{"metadata":{"id":"Cht7dImWwC42","colab_type":"code","colab":{}},"cell_type":"code","source":["nltk.download('universal_tagset')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IiTimRRywC47","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"tagset.png\">"]},{"metadata":{"id":"iyDBMcBSwC48","colab_type":"text"},"cell_type":"markdown","source":["Мы имеем массив предложений пар (слово-тег)"]},{"metadata":{"scrolled":false,"id":"BobflewQwC4-","colab_type":"code","colab":{}},"cell_type":"code","source":["brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n","brown_tagged_sents"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jSu1KqRrwC5L","colab_type":"text"},"cell_type":"markdown","source":["Первое предложение"]},{"metadata":{"id":"zCHCZPlkwC5N","colab_type":"code","colab":{}},"cell_type":"code","source":["brown_tagged_sents[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SIV2MiRxwC5Q","colab_type":"text"},"cell_type":"markdown","source":["Все пары (слово-тег)"]},{"metadata":{"id":"dVx9e9HcwC5R","colab_type":"code","colab":{}},"cell_type":"code","source":["brown_tagged_words = brown.tagged_words(tagset='universal')\n","brown_tagged_words"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y-ADby6LwC5V","colab_type":"text"},"cell_type":"markdown","source":["Проанализируйте данные, с которыми Вы работаете. Используйте `nltk.FreqdDist()` для подсчета частоты встречаемости тега и слова в нашем корпусе. Под частой элемента подразумевается кол-во этого элемента в корпусе."]},{"metadata":{"id":"4giWaqXjwC5W","colab_type":"code","colab":{}},"cell_type":"code","source":["print('Кол-во предложений: ', len(brown_tagged_sents))\n","tags = [tag for (word, tag) in brown_tagged_words] # наши теги\n","words = [word for (word, tag) in brown_tagged_words] # наши слова\n","\n","tag_num = pd.Series('''your code''').sort_values(ascending=False) # тег - кол-во тега с корпусе\n","word_num = pd.Series('''your code''').sort_values(ascending=False) # слово - кол-во слова с корпусе"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yfiPpCcLwC5Z","colab_type":"code","colab":{}},"cell_type":"code","source":["tag_num"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Y1huw7TwC5b","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(12, 5))\n","plt.bar(tag_num.index, tag_num.values)\n","plt.title(\"Tag_frequency\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gBbhnJsmwC5f","colab_type":"code","colab":{}},"cell_type":"code","source":["word_num"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1WmEOBMkwC5i","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(12, 5))\n","plt.bar(word_num.index[:10], word_num.values[:10])\n","plt.title(\"Word_frequency\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n08z2PjMwC5o","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 1:\n","* Кол-во слова `cat` в корпусе?"]},{"metadata":{"id":"jhB7di3YwC5p","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UsCfVLsewC5s","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 2:\n","* Самое популярное слово с самым популярным тегом?"]},{"metadata":{"id":"oio-XBYkwC5t","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K-OGc1rSwC5x","colab_type":"text"},"cell_type":"markdown","source":["Впоследствии обучение моделей может занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."]},{"metadata":{"id":"Eb7MhxVRwC5y","colab_type":"text"},"cell_type":"markdown","source":["Категории нашего корпуса:"]},{"metadata":{"id":"GSiVcP1TwC51","colab_type":"code","colab":{}},"cell_type":"code","source":["brown.categories()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MjSlFatJwC53","colab_type":"text"},"cell_type":"markdown","source":["Будем работать с категорией humor"]},{"metadata":{"id":"_f1rl5x0wC55","colab_type":"text"},"cell_type":"markdown","source":["Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1. "]},{"metadata":{"id":"GX9t-1qowC58","colab_type":"code","colab":{}},"cell_type":"code","source":["my_brown_tagged_sents = np.array(brown.tagged_sents(tagset=\"universal\", categories='humor'))\n","np.random.seed(2)\n","random_index = np.random.choice('''your code''').astype('bool')\n","train_sents = my_brown_tagged_sents[random_index]\n","test_sents = my_brown_tagged_sents[(1 - random_index).astype('bool')]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pXkVwUjYwC5-","colab_type":"code","colab":{}},"cell_type":"code","source":["len(train_sents)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JQMjzJ2YwC6C","colab_type":"code","colab":{}},"cell_type":"code","source":["len(test_sents)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_rEasLVcwC6G","colab_type":"text"},"cell_type":"markdown","source":["### Метод максимального правдоподобия для обучения модели\n","\n","* $\\normalsize S = s_0, s_1, ..., s_N$ - скрытые состояния, то есть различные теги\n","* $\\normalsize O = o_0, o_1, ..., o_M$ - различные слова\n","* $\\normalsize a_{i,j} = p(s_j|s_i)$ - вероятность того, что, находясь в скрытом состоянии $s_i$, мы попадем в состояние $s_j$ (элемент матрицы $A$)\n","* $\\normalsize b_{k,j}=p(o_k|s_j)$ - вероятность того, что, находясь в скрытом состоянии $s_i$,(элемент матрицы $B$)\n","\n","$$\\normalsize x_t \\in O, y_t \\in S$$\n","$\\normalsize (x_t, y_t)$ - слово и тег, стоящие на месте $t$ $\\Rightarrow$ \n","* $\\normalsize X$ - последовательность слов\n","* $\\normalsize Y$ - последовательность тегов\n","\n","Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n","\n","- Вероятности переходов между скрытыми состояниями $p(y_t | y_{t - 1})$ посчитайте на основе частот биграмм POS-тегов.\n","\n","\n","- Вероятности эмиссий наблюдаемых состояний $p(x_t | y_t)$ посчитайте на основе частот \"POS-тег - слово\".\n","\n","\n","- Распределение вероятностей начальных состояний $p(y_0)$ задайте равномерным.\n"]},{"metadata":{"id":"tysPoe5rwC6I","colab_type":"text"},"cell_type":"markdown","source":["#### Алгоритм Витерби для применения модели\n","\n","\n","Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n","\n","$$ \\hat{Y} = \\arg \\max_{Y} p(Y|X) = \\arg \\max_{Y} p(Y, X) $$\n","\n","Пусть $\\normalsize Q_{t,s}$ - самая вероятная последовательность скрытых состояний длины $t$ с окончанием в состоянии $s$. $\\normalsize q_{t, s}$ - вероятность этой последовательности.\n","$$(1)\\: \\normalsize q_{t,s} = \\max_{s'} q_{t - 1, s'} \\cdot p(s | s') \\cdot p(o_t | s)$$\n","$\\normalsize Q_{t,s}$ можно восстановить по argmax-ам."]},{"metadata":{"id":"QpEXdhOfwC6J","colab_type":"code","colab":{}},"cell_type":"code","source":["class HiddenMarkovModel:    \n","    def __init__(self):\n","    \n","        pass\n","        \n","    def fit(self, train_tokens_tags_list):\n","        \"\"\"\n","        train_tokens_tags_list: массив предложений пар слово-тег (выборка для train) \n","        \"\"\"\n","        tags = [tag for sent in train_tokens_tags_list\n","                for (word, tag) in sent]\n","        words = [word for sent in train_tokens_tags_list\n","                 for (word, tag) in sent]\n","        \n","        tag_num = pd.Series('''your code''').sort_index()\n","        word_num = pd.Series('''your code''').sort_values(ascending=False)\n","         \n","        self.tags = tag_num.index\n","        self.words = word_num.index\n","        \n","        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n","        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n","        \n","        # Вычисляем матрицу A и B по частотам слов и тегов\n","        \n","        # sent - предложение\n","        # sent[i][0] - i слово в этом предложении, sent[i][1] - i тег в этом предложении\n","        for sent in train_tokens_tags_list:\n","            for i in range(len(sent)):\n","                B.loc['''your code'''] += 1 # текущая i-пара слово-тег (обновите матрицу B аналогично A)\n","                if len(sent) - 1 != i: # для последнего тега нет следующего тега\n","                    A.loc[sent[i][1], sent[i + 1][1]] += 1 # пара тег-тег\n","                \n","        \n","        # переходим к вероятностям\n","        \n","        # нормируем по строке, то есть по всем всевозможным следующим тегам\n","        A = A.divide(A.sum(axis=1), axis=0)\n","        \n","        # # нормируем по столбцу, то есть по всем всевозможным текущим словам\n","        B = B / np.sum(B, axis=0)\n","        \n","        self.A = A\n","        self.B = B\n","        \n","        return self\n","        \n","    \n","    def predict(self, test_tokens_list):\n","        \"\"\"\n","        test_tokens_list : массив предложений пар слово-тег (выборка для test)\n","        \"\"\"\n","        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n","        \n","        for i_sent in range(len(test_tokens_list)):\n","            \n","            current_sent = test_tokens_list[i_sent] # текущее предложение\n","            len_sent = len(current_sent) # длина предложения \n","            \n","            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n","            q[0] = 1 # нулевое состояние (равномерная инициализация по всем s)\n","            back_point = np.zeros(shape=(len_sent + 1, len(self.tags))) # # argmax\n","            \n","            for t in range(len_sent):\n","                \n","                # если мы не встречали такое слово в обучении, то вместо него будет \n","                # самое популярное слово с самым популярным тегом (вопрос 2)\n","                if current_sent[t] not in self.words:\n","                    current_sent[t] = '''your code'''\n","                    \n","                # через max выбираем следующий тег\n","                for i_s in range(len(self.tags)):\n","                    \n","                    s = self.tags[i_s]\n","                    \n","                    # формула (1)\n","                    q[t + 1][i_s] = np.max(q['''your code'''] *\n","                        self.A.loc[:, '''your code'''] * \n","                        self.B.loc[current_sent[t], s])\n","                    \n","                    # argmax формула(1)\n","                    \n","                    # argmax, чтобы восстановить последовательность тегов\n","                    back_point[t + 1][i_s] = (q['''your code'''] * self.A.loc[:, '''your code'''] * \n","                        self.B.loc[current_sent[t],s]).reset_index()[s].idxmax() # индекс \n","                    \n","            back_point = back_point.astype('int')\n","            \n","            # выписываем теги, меняя порядок на реальный\n","            back_tag = deque()\n","            current_tag = np.argmax(q[len_sent])\n","            for t in range(len_sent, 0, -1):\n","                back_tag.appendleft(self.tags[current_tag])\n","                current_tag = back_point[t, current_tag]\n","             \n","            predict_tags[i_sent] = np.array(back_tag)\n","        \n","        \n","        return predict_tags\n","                \n","        \n","                    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"y0BLgsWkwC6M","colab_type":"text"},"cell_type":"markdown","source":["Обучите скрытую марковскую модель:"]},{"metadata":{"id":"ZcSoyUAxwC6M","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FeVNt19kwC6P","colab_type":"text"},"cell_type":"markdown","source":["Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n","\n","- 'He can stay'\n","- 'a cat and a dog'\n","- 'I have a television'\n","- 'My favourite character'"]},{"metadata":{"id":"cMJErf7NwC6Q","colab_type":"code","colab":{}},"cell_type":"code","source":["sents = [['He', 'can', 'stay'], ['a', 'cat', 'and', 'a', 'dog'], ['I', 'have', 'a', 'television'],\n","         ['My', 'favourite', 'character']]\n","'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"suDCwbGMwC6T","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 3:\n","* Какой тег вы получили для слова `can`?"]},{"metadata":{"id":"ReHeG3IjwC6U","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ObAslurlwC6X","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 4:\n","* Какой тег вы получили для слова `favourite`?"]},{"metadata":{"id":"94crVrrXwC6Y","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YPC4NZ4HwC6a","colab_type":"text"},"cell_type":"markdown","source":["Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "]},{"metadata":{"id":"-7aioBc1wC6b","colab_type":"code","colab":{}},"cell_type":"code","source":["k_full = 0.0\n","k_right = 0.0\n","for sent in test_sents:\n","    tags = np.array(['''your code'''])\n","    words = np.array(['''your code'''])\n","    predict_tags = '''your model'''.predict([words])[0]\n","    k_right += np.sum(tags == '''your code''')\n","    k_full += '''your code'''\n","print(\"Accuracy:\", k_right / k_full * 100, '%')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ff_W7J8XwC6e","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 5:\n","* Какое качество вы получили(округлите до одного знака после запятой)?"]},{"metadata":{"id":"ptvlpc-6wC6f","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FpAgfZRTwC6h","colab_type":"text"},"cell_type":"markdown","source":["## DefaultTagger"]},{"metadata":{"id":"9b4cPKyiwC6j","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 6:\n","* Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)?"]},{"metadata":{"id":"Td-0Pe0vwC6k","colab_type":"text"},"cell_type":"markdown","source":["Вы можете испоьзовать DefaultTagger(метод tag для предсказания частей речи предложения) или можете преобразовать код выше"]},{"metadata":{"id":"NfZYlMxJwC6m","colab_type":"code","colab":{}},"cell_type":"code","source":["from nltk.tag import DefaultTagger\n","default_tagger = DefaultTagger('''your code''')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lz7Q3BfbwC6o","colab_type":"text"},"cell_type":"markdown","source":["## Модель Стенфорда"]},{"metadata":{"id":"eKYPKJYLwC6p","colab_type":"text"},"cell_type":"markdown","source":["Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. \n","Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."]},{"metadata":{"id":"yW-PR54QwC6p","colab_type":"code","colab":{}},"cell_type":"code","source":["from nltk.tag.stanford import StanfordPOSTagger\n","from nltk.tag.mapping import map_tag\n","\n","# используйте путь до jar и до model\n","jar = 'your_path/stanford-postagger-2018-10-16/stanford-postagger-3.9.2.jar'\n","model = 'your_path/stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger'\n","stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n","\n","# проверим на предложении\n","tagged_sent = stanford_tagger.'''your code'''(['I', 'bear', 'a', 'bag'])\n","print('Ответ: ', [map_tag() for token, tag in tagged_sent])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i1z8x4vvwC6s","colab_type":"text"},"cell_type":"markdown","source":["### Вопрос 7:\n","* Какое качество вы получили на модели Стенфорда(округлите до одного знака после запятой)?"]},{"metadata":{"id":"GBd3RgqVwC6s","colab_type":"code","colab":{}},"cell_type":"code","source":["'''your code'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zMIJDOBmwC6v","colab_type":"text"},"cell_type":"markdown","source":["## Сравните результаты моделей"]}]}