{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[seminar]text_to_speech.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9JC4Lqb9HZ7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:90px;\" width=500/></p>\n",
        "\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "metadata": {
        "id": "V8JKthGHHbhz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "KIhqwe8PNta_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Text to speech: семинар"
      ]
    },
    {
      "metadata": {
        "id": "o7F_KOLiHbkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Привет! \n",
        "\n",
        "В этом ноутбуке мы позапускаем модели, которые были описаны на лекции: Tacotron, WaveNet, DeepVoice. Обучать сами в этот раз ничего не будем, поскольку нормальные модели для text-to-speech обучаются как минимум сутки (но это не говорит о том, что не нужно пытаться обучать -- просто в рамках занятия не успеем это сделать до нормального качества физически)."
      ]
    },
    {
      "metadata": {
        "id": "09KgRdHDINIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://s.tcdn.co/163/0f3/1630f39d-45fe-3d77-8d1d-1b2cf25f380d/1.png\" width=300>"
      ]
    },
    {
      "metadata": {
        "id": "y7f9BsRRIR71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Напомню, задача стоит так: **по входному тексту (набору символов) получить на выходе аудиофайл, в котором человек тем или иным голосом произносит данный текст**, то есть задача **text-to-speech**.  \n",
        "\n",
        "Сразу можно заметить, что постановка уже подразумевает несколько трактовок: с какой именно интонацией произнести? каким именно голосом? акцент? паузы? скорость речи?\n",
        "\n",
        "Всё это определяется уже на этапе генерации речи нашей моделью."
      ]
    },
    {
      "metadata": {
        "id": "YIzfAF6JNrHl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Небольшое введение"
      ]
    },
    {
      "metadata": {
        "id": "eInEx1w0NrJ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Чтобы лучше разобраться, что вообще подаётся на вход и как работать со звуком в цифровом виде, всем очень рекомендую прочитать [статью от Центра Речевых Технологий (ЦРТ)](https://habr.com/ru/company/speechpro/blog/358816/), это очень хорошая статья про генерацию речи с помощью DCTTS своими руками.\n",
        "\n",
        "В целом как обзор методов, которые были раньше (конкатенационные и параметрические), и как обзор некоторых современных методов, неплоха [эта статья](https://medium.com/@saxenauts/speech-synthesis-techniques-using-deep-neural-networks-38699e943861).  \n"
      ]
    },
    {
      "metadata": {
        "id": "qaYVlINFtqp4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Если выделить ключевые вещи, которые надо понимать при обработке звука, то они могут выглядеть так:\n",
        "1. Понимание того, как устроена запись звука (опционально)\n",
        "2. Библиотека [librosa](http://librosa.github.io/librosa )\n",
        "3. Примерное понимание того, что такое преобразование Фурье и почему оно здесь эффективно. Про него можно почитать [здесь](https://habr.com/ru/post/196374/) и [здесь](https://habr.com/ru/post/269991/)"
      ]
    },
    {
      "metadata": {
        "id": "A19-7gRlNrMF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Нейросети для генерации речи"
      ]
    },
    {
      "metadata": {
        "id": "cwHo8sS3wPIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Мы рассмотрим модели:\n",
        "1. WaveNet  \n",
        "2. Tacotron\n",
        "3. Tacotron 2\n",
        "4. Deep Voice 3\n",
        "5. DCTTS (кратко)\n",
        "\n",
        "Везде далее надо держать в голове, что есть два этапа в end2end TTS (да, звучит противоречиво, ведь это end2end=):\n",
        "1. Преобразование текста в спектрограммы \n",
        "2. Получение по спектрограммам waveform, а потом из них аудиофайла (этой часть занимаются так называемые **vocoder'ы**)\n",
        "\n",
        "Для 1 используют Tacotron первой версии, для 2 WaveNet первой версии. Также для 2 используют алгоритм Гриффина-Лима.\n",
        "\n",
        "Сначала было Tacotron 1 + Griffin-Lim, потом придумали Tacotron 2, который совместил в себе Tacotron 1 и WaveNet.\n",
        "\n",
        "Также есть DeepVoice, который как Tacotron 1. DCTTS тоже как Tacotron 1 (они  используют постобработку спектрограмм в вейвформы, а сами предсказывают эти самые спектрограммы)."
      ]
    },
    {
      "metadata": {
        "id": "pTPatj5lRk2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Из датасетов важно знать TIMIT, LibriSpeech и [LJ-Speech](https://keithito.com/LJ-Speech-Dataset/)."
      ]
    },
    {
      "metadata": {
        "id": "qZckZinPNrN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### WaveNet"
      ]
    },
    {
      "metadata": {
        "id": "DZ1471U9JPE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.ytimg.com/vi/GO_2aVqZlQs/hqdefault.jpg\" width=300>"
      ]
    },
    {
      "metadata": {
        "id": "gODMKZdkUxMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[WaveNet](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) была одна из первых архитектур, придуманных для генарции речи из полученных по тексту фонем. Она [была опубикована 19 сентября 2016 года](https://arxiv.org/pdf/1609.03499.pdf) компанией DeepMind (сейчас является частью Google).\n",
        "\n",
        "Одна из самых популярных реализаций -- реализация на TensorFlow: https://github.com/ibab/tensorflow-wavenet. Однако, как можно заметить в репозитории, эта модель позволяет генрировать речь несвязно, то есть не по тексту, а просто из шума, но там даже есть условие на то, кто именно будет произносить эту речь (Global Conditionng).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9YOH9HzRUxOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Мы всё же хотим генерировать аудио из текста, WaveNet сам по себе для этого не подходит. Передём к моделям, которые позволят это делать."
      ]
    },
    {
      "metadata": {
        "id": "0crZvhFqQgD0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Также рекомендую прочитать [более современную статью по WaveNet](https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1), в том числе про Parallel WaveNet."
      ]
    },
    {
      "metadata": {
        "id": "C_BdF-OQZ0Hj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tacotron"
      ]
    },
    {
      "metadata": {
        "id": "gCBL6bzFJVHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://memepedia.ru/wp-content/uploads/2018/10/jv5l3v9svse-1-kopiya.jpg\" width=300>"
      ]
    },
    {
      "metadata": {
        "id": "S2o_lr_UZ0Jv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Tacotron](https://arxiv.org/pdf/1703.10135.pdf) был опубликован 16 апреля 2017 года компанией Google. \n",
        "\n",
        "Здесь есть https://github.com/keithito/tacotron (1300+ звёзд на гитхбе) и https://github.com/Kyubyong/tacotron (1400+ звёзд), попробуем запустить первый/"
      ]
    },
    {
      "metadata": {
        "id": "FriTNQn5Z1vv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/keithito/tacotron tacotron_1\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fVtAcvjkeMRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('./tacotron_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6_fmjOgrd_8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RspTyyCSeALa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!curl http://data.keithito.com/data/speech/tacotron-20180906.tar.gz | tar xzC /tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JthvwOOAepFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 demo_server.py --checkpoint /tmp/tacotron-20180906/model.ckpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VqqCbyxfwYB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "У себя на компьютере это сработало бы, но с колаба сервер не запустить (по крайней мере, это не просто сделать). Попробуем второй:"
      ]
    },
    {
      "metadata": {
        "id": "3yOzOdGfglXN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsFzf245epH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Kyubyong/tacotron tacotron_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ColATr72f61x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSOsE65zf33n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('./tacotron_2/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKucC4gCf36S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python synthesize.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfqpa4hAkIe8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ошибка, потому что мы не указали, из какой папки брать вес предобученной модели. Скачаем их и положим в нужную папку:"
      ]
    },
    {
      "metadata": {
        "id": "8G7cygYwf3-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/8kxa3xh2vfna3s9/LJ_logdir.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z55PIWm4kpyc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4U6QE5Ukxwz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip LJ_logdir.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUqIAwCXk1NU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pWQOkbDRk1f8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv LJ logdir\n",
        "!mkdir logdir/01\n",
        "!mv logdir/* logdir/01\n",
        "!ls logdir/01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MM8o-9SRlckL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Снова попробуем запустить:"
      ]
    },
    {
      "metadata": {
        "id": "YZyuUhgjlFQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python synthesize.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ecjrVd8PlFUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls samples/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4568YUhplFSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for i in range(1, 21):\n",
        "    files.download(f'samples/{i}.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4wBH7VQ0nTKX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Если послушать, то получилось вполне неплохо.\n",
        "\n",
        "Итак, мы сделали следующее:\n",
        "1. Написали текст на вход\n",
        "2. Нормализовали текст, закодировали символы через char2idx\n",
        "3. Подали на вход Tacotron'у \n",
        "4. Получили на выходе из Tacotron'а mel-спектрограммы\n",
        "5. Преобразовали их в waveform'ы с помощью алгоритма [Гриффина-Лима](https://github.com/Kyubyong/tacotron/blob/379bb7f54c3359ffe97d1f09a773bc6da49eba6f/utils.py#L107)\n",
        "6. Произвели постобработку, получили .wav-файлы"
      ]
    },
    {
      "metadata": {
        "id": "Zil14_2DpaXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Попробуем написать  свой текст:"
      ]
    },
    {
      "metadata": {
        "id": "cXoY3d9cpYQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "HEADER = 'http://www.cs.columbia.edu/~hgs/audio/harvard.html\\n'\n",
        "MY_TEXTS = [\n",
        "    '1. Deep Learning School is the best place to study the neural networks.\\n',\n",
        "    '2. AI, BigData, Blockchain, Agile.\\n',\n",
        "    '3. MIPT PSAMI is not about dogs, it stands for Phystech-School of Mathematics and Informatics.\\n'\n",
        "]\n",
        "with open('harvard_sentences.txt', 'w') as texts_file:\n",
        "    texts_file.write(HEADER)\n",
        "    for text in MY_TEXTS:\n",
        "        texts_file.write(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-Xf1S_2qd-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat harvard_sentences.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xk6P8p_OqeA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python synthesize.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Dn0_Mcxqkee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for i in range(1, 4):  # сейчас только 1.wav, 2.wav и 3.wav перезаписались\n",
        "    files.download(f'samples/{i}.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnYGQJetZqxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tacotron 2"
      ]
    },
    {
      "metadata": {
        "id": "I6A64csXJddW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://memestatic1.fjcdn.com/comments/Your+grandma+is+a+fox+_1b9c90c0bd43b76f2f364a3b424a1260.jpg\" width=300>"
      ]
    },
    {
      "metadata": {
        "id": "vi7X1vAiLHJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Tacotron 2](https://arxiv.org/pdf/1712.05884.pdf) появился 16 февраля 2018 года, разработан компанией Google (совместно с DeepMind)."
      ]
    },
    {
      "metadata": {
        "id": "zYSkHa9hZ2TZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Поищем реализации. С виду очень хороший репозиторий: https://github.com/Rayhane-mamah/Tacotron-2 \n",
        "\n",
        "В нём хорошо описано всё, что нужно для загрузки и предобработки датасета, а также обучения и тестирования модели. Мы могли бы его позапускать, но есть **нюанс -- нет предобученных весов**, придётся оубчать с нуля (а мы хотим поскорее запустить) :(\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "G3gPas7NI9tN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/Rayhane-mamah/Tacotron-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNDaEkeRI9vZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !apt-get install -y libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg libav-tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w-vdrTjJI91K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip3 install -r Tacotron-2/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GrwnlFO9HaQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZJ0EeFjtXpH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**НО**: есть ещё один классный репозиторий https://github.com/r9y9/wavenet_vocoder, там есть ноутбуки на колабе (перейдём туда)."
      ]
    },
    {
      "metadata": {
        "id": "BXadjKx1tZdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Deep Voice 3"
      ]
    },
    {
      "metadata": {
        "id": "8EGfvlCKRxA-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://78.media.tumblr.com/b26d78d8fcfcdc98ede414f079d71215/tumblr_inline_npzymfyFPt1sh39fc_500.jpg\" width=300>"
      ]
    },
    {
      "metadata": {
        "id": "wcBqCbjMJnzo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Deep Voice 3](https://arxiv.org/pdf/1710.07654.pdf) был опубикован 20 февраля 2018 года совместно Baidu, OpenAI и Университетом Беркли."
      ]
    },
    {
      "metadata": {
        "id": "8Gv0XyqVtd2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Идеальный репозиторий с колаб-ноутбуком, готовым для запуска: https://github.com/r9y9/deepvoice3_pytorch (в него и перейдём)"
      ]
    },
    {
      "metadata": {
        "id": "2bNOON3kME9N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DCTTS"
      ]
    },
    {
      "metadata": {
        "id": "5Emiv1ztMFUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "По этой модели написана [статья на Хабре от ЦРТ](https://habr.com/ru/company/speechpro/blog/358816/), плюс есть хороший репозиторий: https://github.com/Kyubyong/dc_tts, на ней останавливаться не будем (по функциональности делает то же, что и Tacotron)."
      ]
    },
    {
      "metadata": {
        "id": "8nxSetoJs2KX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ещё"
      ]
    },
    {
      "metadata": {
        "id": "nJtr2BqytCZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ещё есть Mozilla TTS: https://github.com/mozilla/TTS и OpenSeq2Seq от NVIDIA: https://nvidia.github.io/OpenSeq2Seq/, безусловно, очень полезные библиотеки, попробуйте потестить их самостоятельно.   \n",
        "\n",
        "если хочется погрузиться в более классические методы обработки звуки фундаментально, то можно пройти [курс от Стэнфорда](https://web.stanford.edu/class/cs224s/syllabus.html)\n",
        "\n",
        "А мы движемся к ещё более горячей теме :)"
      ]
    },
    {
      "metadata": {
        "id": "JEfvpJiPtCbH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Генерация музыки"
      ]
    },
    {
      "metadata": {
        "id": "UjKyIh1OOSv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.nastol.com.ua/pic/201209/1920x1080/nastol.com.ua-31871.jpg\" width=400> "
      ]
    },
    {
      "metadata": {
        "id": "tiY5OvaF2Kmk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "На эту тему будет домашнее задание, подробнее там.\n",
        "\n",
        "Ссылки, по которым стоит пройтись:\n",
        "\n",
        "* ШОК ЧИТАТЬ ВСЕМ: https://openai.com/blog/musenet/\n",
        "* https://salu133445.github.io/musegan/\n",
        "* https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn\n",
        "* https://en.wikipedia.org/wiki/ABC_notation\n",
        "* [Статья про генерацию музыки RNN-кой](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5)"
      ]
    }
  ]
}