{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[seminar]convnet_pytorch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"hoxBEVcAmvQF","colab_type":"text"},"cell_type":"markdown","source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:90px;\" width=500/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"metadata":{"id":"fqKI3PvQqk-x","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"0Q6NgIGBmvQH","colab_type":"text"},"cell_type":"markdown","source":["В этом ноутбке мы научимся писать свои свёрточные нейросети на фреймворке PyTorch, и протестируем их работу на датасетах MNIST и CIFAR10. \n","\n","**ВНИМАНИЕ:** Рассматривается ***задача классификации изображений***.\n","\n","(Подразумевается, что читатель уже знаком с многослойной нейроннной сетью).  \n","\n","***Свёрточная нейросеть (Convolutional Neural Network, CNN)*** - это многослойная нейросеть, имеющая в своей архитектуре помимо *полносвязных слоёв* (а иногда их может и не быть) ещё и **свёрточные слои (Conv Layers)** и **pooling-слои (Pool Layers)**.  \n","\n","Собственно, название такое эти сети получили потому, что в основе их работы лежит операция **свёртки**. \n","\n","\n","Сразу же стоит сказать, что свёрточные нейросети **были придуманы прежде всего для задач, связанных с картинками**, следовательно, на вход они тоже \"ожидают\" картинку.\n","\n","Расмотрим их устройство более подробно:\n","\n","* Вот так выглядит неглубокая свёрточная нейросеть, имеющая такую архитектуру:  \n","`Input -> Conv 5x5 -> Pool 2x2 -> Conv 5x5 -> Pool 2x2 -> FC -> Output`\n","\n","<img src=\"https://camo.githubusercontent.com/269e3903f62eb2c4d13ac4c9ab979510010f8968/68747470733a2f2f7261772e6769746875622e636f6d2f746176677265656e2f6c616e647573655f636c617373696669636174696f6e2f6d61737465722f66696c652f636e6e2e706e673f7261773d74727565\" width=800, height=600>\n","\n","Свёрточные нейросети (обыкновенные, есть и намного более продвинутые) почти всегда строятся по следующему правилу:  \n","\n","`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC`  \n","\n","то есть:  \n","\n","1). ***Входной слой*** (batch картинок `HxWxC`)  \n","\n","2). $M$ блоков (M $\\ge$ 0) из свёрток и pooling-ов, причём именно в том порядке, как в формуле выше. Все эти $M$ блоков вместе называют ***feature extractor*** свёрточной нейросети, потому что эта часть сети отвечает непосредственно за формирование новых, более сложных признаков, поверх тех, которые подаются (то есть, по аналогии с MLP, мы опять же переходим к новому признаковому пространству, однако здесь оно строится сложнее, чтем в обычных многослойных сетях, поскольку используется операция свёртки)  \n","\n","3). $K$ штук FullyConnected-слоёв (с активациями). Эту часть из $K$ FC-слоёв называют ***classificator***, поскольку эти слои отвечают непосредственно за предсказание нужно класса (сейчас рассматривается задача классификации изображений)."]},{"metadata":{"id":"RUh08RELmvQI","colab_type":"text"},"cell_type":"markdown","source":["\n","<h3 style=\"text-align: center;\"><b>Свёрточная нейросеть на PyTorch</b></h3>\n","\n","Ешё раз напомним про основные компоненты нейросети:\n","\n","- непосредственно, сама **архитектура** нейросети (сюда входят типы функций активации у каждого нейрона);\n","- начальная **инициализация** весов каждого слоя;\n","- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n","- размер **батчей** (`batch_size`);\n","- количетсво итераций обучения (`num_epochs`);\n","- **функция потерь** (`loss`);  \n","- тип **регуляризации** нейросети (для каждого слоя можно свой);  \n","\n","То, что связано с ***данными и задачей***:  \n","- само **качество** выборки (непротиворечивость, чистота, корректность постановки задачи);  \n","- **размер** выборки;  \n","\n","Так как мы сейчас рассматриваем **архитектуру CNN**, то, помимо этих компонент, в свёрточной нейросети можно настроить следующие вещи:  \n","\n","- (в каждом ConvLayer) **размер фильтров (окна свёртки)** (`kernel_size`)\n","- (в каждом ConvLayer) **количество фильтров** (`out_channels`)  \n","- (в каждом ConvLayer) размер **шага окна свёртки (stride)** (`stride`)  \n","- (в каждом ConvLayer) **тип padding'а** (`padding`)  \n","\n","\n","- (в каждом PoolLayer) **размер окна pooling'a** (`kernel_size`)  \n","- (в каждом PoolLayer) **шаг окна pooling'а** (`stride`)  \n","- (в каждом PoolLayer) **тип pooling'а** (`pool_type`)  \n","- (в каждом PoolLayer) **тип padding'а** (`padding`)"]},{"metadata":{"id":"aPy6-6kpmvQK","colab_type":"text"},"cell_type":"markdown","source":["Какими их берут обычно -- будет показано в примере ниже. По крайней мере, можете стартовать с этих настроек, чтобы понять, какое качество \"из коробки\" будет у простой модели."]},{"metadata":{"id":"arl2FqAfmvQL","colab_type":"text"},"cell_type":"markdown","source":["Посмотрим, как работает CNN на MNIST'е и на CIFAR'е:"]},{"metadata":{"id":"ly4hPj7DmvQM","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"http://present5.com/presentation/20143288_415358496/image-8.jpg\" width=500, height=400>"]},{"metadata":{"id":"94s_K_pAmvQN","colab_type":"text"},"cell_type":"markdown","source":["**MNIST:** это набор из 70k картинок рукописных цифр от 0 до 9, написанных людьми, 60k из которых являются тренировочной выборкой (`train` dataset)), и ещё 10k выделены для тестирования модели (`test` dataset)."]},{"metadata":{"id":"O1tqZNdWmvQN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":376},"outputId":"dd6c7d19-2350-4b53-de7f-588ca4532d61","executionInfo":{"status":"error","timestamp":1541754216636,"user_tz":-180,"elapsed":615,"user":{"displayName":"Михаил Владимирович Макаров","photoUrl":"","userId":"00571021236711414160"}}},"cell_type":"code","source":["import torch\n","import torchvision\n","from torchvision import transforms\n","\n","import numpy as np\n","import matplotlib.pyplot as plt  # для отрисовки картиночек\n","%matplotlib inline"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-fc0f6bd2228b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"kXXOvRS1mvQS","colab_type":"text"},"cell_type":"markdown","source":["Скачаем и загрузим в `loader`'ы:"]},{"metadata":{"id":"jmCjo8CjmvQT","colab_type":"text"},"cell_type":"markdown","source":["**Обратите внимание на аргумент `batch_size`:** именно он будет отвечать за размер батча, который будет подаваться при оптимизации нейросети"]},{"metadata":{"id":"DpjaLS99mvQV","colab_type":"code","colab":{}},"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor()])\n","\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, \n","                                      download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                     download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = tuple(str(i) for i in range(10))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mqtRMMqwmvQa","colab_type":"text"},"cell_type":"markdown","source":["Сами данные лежат в полях `trainloader.dataset.train_data` и `testloader.dataset.test_data`:"]},{"metadata":{"scrolled":true,"id":"NxnQI-7FmvQc","colab_type":"code","colab":{}},"cell_type":"code","source":["trainloader.dataset.train_data.shape"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"-rt0UBALmvQf","colab_type":"code","colab":{}},"cell_type":"code","source":["testloader.dataset.test_data.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aj4QmKwDmvQk","colab_type":"text"},"cell_type":"markdown","source":["Выведем первую картинку:"]},{"metadata":{"scrolled":true,"id":"nBAKbazhmvQm","colab_type":"code","colab":{}},"cell_type":"code","source":["trainloader.dataset.train_data[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U7YqZYacmvQq","colab_type":"text"},"cell_type":"markdown","source":["Посмотрим, как она выглядит:"]},{"metadata":{"id":"SHxq21ydmvQq","colab_type":"code","colab":{}},"cell_type":"code","source":["# преобразовать тензор в np.array\n","numpy_img = trainloader.dataset.train_data[0].numpy()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Lz-SfUuOmvQt","colab_type":"code","colab":{}},"cell_type":"code","source":["numpy_img.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kAxc-OjwmvQy","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.imshow(numpy_img);"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jo1SInrpmvQ2","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.imshow(numpy_img, cmap='gray');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OW3JZteDmvQ7","colab_type":"text"},"cell_type":"markdown","source":["Отрисовка заданной цифры:"]},{"metadata":{"id":"VC-xcS7rmvQ7","colab_type":"code","colab":{}},"cell_type":"code","source":["# случайный индекс от 0 до размера тренировочной выборки\n","i = np.random.randint(low=0, high=60000)\n","\n","plt.imshow(trainloader.dataset.train_data[i].numpy(), cmap='gray');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e9DOvlk1mvRB","colab_type":"text"},"cell_type":"markdown","source":["Как итерироваться по данным с помощью `loader'`а? Очень просто:"]},{"metadata":{"scrolled":true,"id":"V73spLIAmvRD","colab_type":"code","colab":{}},"cell_type":"code","source":["for data in trainloader:\n","    print(data)\n","    break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5gLVfQsLmvRI","colab_type":"text"},"cell_type":"markdown","source":["То есть мы имеем дело с кусочками данных размера batch_size (в данном случае = 4), причём в каждом батче есть как объекты, так и ответы на них (то есть и $X$, и $y$)."]},{"metadata":{"id":"sftGrFWvmvRK","colab_type":"text"},"cell_type":"markdown","source":["Теперь вернёмся к тому, что в PyTorch есть две \"парадигмы\" построения нейросетей -- `Functional` и `Seuquential`. Со второй мы уже хорошенько разобрались в предыдущих ноутбуках по нейросетям, теперь мы испольузем именно `Functional` парадигму, потому что при построении свёрточных сетей это намного удобнее:"]},{"metadata":{"id":"JjaimqEhmvRM","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F  # Functional"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JOY8j76OmvRP","colab_type":"code","colab":{}},"cell_type":"code","source":["# ЗАМЕТЬТЕ: КЛАСС НАСЛЕДУЕТСЯ ОТ nn.Module\n","class SimpleConvNet(nn.Module):\n","    def __init__(self):\n","        # вызов конструктора предка\n","        super(SimpleConvNet, self).__init__()\n","        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n","        # которую будем подавать в сеть, больше ничего\n","        # про входящие картинки знать не нужно\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n","        self.fc1 = nn.Linear(4 * 4 * 16, 120)  # !!!\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        # print(x.shape)\n","        x = x.view(-1, 4 * 4 * 16)  # !!!\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RDc3BlhPmvRR","colab_type":"text"},"cell_type":"markdown","source":["**Важное примечание:** Вы можете заметить, что в строчках с `#!!!` есть не очень понятный сходу 4 `*` 4 `*` 16. Это -- размерность картинки перед FC-слоями (H x W x C), тут её приходиться высчитывать вручную (в Keras, например, `.Flatten()` всё делает за Вас). Однако есть один *лайфхак* -- просто сделайте в `forward()` `print(x.shape)` (закомментированная строка). Вы увидите размер `(batch_size, C, H, W)` -- нужно перемножить все, кроме первого (batch_size), это и будет первая размерность `Linear()`, и именно в C * H * W нужно \"развернуть\" x перед подачей в `Linear()`.  \n","\n","То есть нужно будет запустить цикл с обучением первый раз с `print()` и сделать после него `break`, посчитать размер, вписать его в нужные места и стереть `print()` и `break`."]},{"metadata":{"id":"tyg446camvRS","colab_type":"text"},"cell_type":"markdown","source":["Код обучения слоя:"]},{"metadata":{"id":"BtBorLrrmvRT","colab_type":"code","colab":{}},"cell_type":"code","source":["from tqdm import tqdm_notebook"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"ja5vFAvWmvRY","colab_type":"code","colab":{}},"cell_type":"code","source":["# объявляем сеть\n","net = SimpleConvNet()\n","\n","# выбираем функцию потерь\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# выбираем алгоритм оптимизации и learning_rate\n","learning_rate = 1e-4\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","\n","# итерируемся\n","for epoch in tqdm_notebook(range(3)):\n","\n","    running_loss = 0.0\n","    for i, batch in enumerate(tqdm_notebook(trainloader)):\n","        # так получаем текущий батч\n","        X_batch, y_batch = batch\n","        \n","        # обнуляем веса\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        y_pred = net(X_batch)\n","        loss = loss_fn(y_pred, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # выведем текущий loss\n","        running_loss += loss.item()\n","        # выведем качество каждые 2000 батчей\n","        if i % 2000 == 1999:\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Обучение закончено')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sJ8up_fZmvRc","colab_type":"text"},"cell_type":"markdown","source":["Протестируем на всём тестовом датасете, используя метрику accuracy_score:"]},{"metadata":{"id":"RJc3Zea2mvRc","colab_type":"code","colab":{}},"cell_type":"code","source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        y_pred = net(images)\n","        _, predicted = torch.max(y_pred, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(10):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_83Wbv_UmvRf","colab_type":"text"},"cell_type":"markdown","source":["Два свёрточных слоя побили многослойную нейросеть. Не магия ли?"]},{"metadata":{"id":"ca7_nhaCmvRg","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"LPxtwt8DmvRi","colab_type":"text"},"cell_type":"markdown","source":["### Задача 1"]},{"metadata":{"id":"2TQgBg3KmvRm","colab_type":"text"},"cell_type":"markdown","source":["Протестируйте эту нейросеть на отдельных картинках из тестового датасета: напишите функцию, которая принимает индекс картинки в тестовом датасете, отрисовывает её, потом запускает на ней модель (нейросеть) и выводит результат предсказания."]},{"metadata":{"id":"UE1hoLa_mvRn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Ваш код здесь"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JUKgvCXhmvRq","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"cr4ftiAGmvRq","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>CIFAR10</b></h3>"]},{"metadata":{"id":"i5ndS6LomvRt","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png\" width=500, height=400>"]},{"metadata":{"id":"zxEQYnT9mvRt","colab_type":"text"},"cell_type":"markdown","source":["**CIFAR10:** это набор из 60k картинок 32х32х3, 50k которых составляют обучающую выборку, и оставшиеся 10k - тестовую. Классов в этом датасете 10: `'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'`.\n","\n","Скачаем и загрузим в `loader`'ы:\n","\n","**Обратите внимание на аргумент `batch_size`:** именн он будет отвечать за размер батча, который будет подаваться при оптимизации нейросети"]},{"metadata":{"id":"KEH8UgeFmvRu","colab_type":"code","colab":{}},"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-IxjpMXfmvRy","colab_type":"code","colab":{}},"cell_type":"code","source":["# случайный индекс от 0 до размера тренировочной выборки\n","i = np.random.randint(low=0, high=50000)\n","\n","plt.imshow(trainloader.dataset.train_data[i], cmap='gray');"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xAUH5D9tmvR0","colab_type":"text"},"cell_type":"markdown","source":["То есть мы имеем дело с кусочками данных размера batch_size (в данном случае = 4), причём в каждом батче есть как объекты, так и ответы на них (то есть и $X$, и $y$).\n","\n","Данные готовы, мы даже на них посмотрели. **Однако учтите** - при подаче в нейросеть мы будем разворачивать картинку 32х32х3 в строку 1х(32`*`32`*`3) = 1х3072, то есть мы считаем пиксели (значения интенсивности в пикселях) за признаки нашего объекта (картинки).  \n","\n","К делу:"]},{"metadata":{"id":"yIzpcJkZmvR2","colab_type":"text"},"cell_type":"markdown","source":["### Задача 2"]},{"metadata":{"id":"FEzw5SbZmvR3","colab_type":"text"},"cell_type":"markdown","source":["Напишите свою свёрточную нейросеть для предсказания на CIFAR10."]},{"metadata":{"id":"oCVhQM1mmvR3","colab_type":"code","colab":{}},"cell_type":"code","source":["# ЗАМЕТЬТЕ: КЛАСС НАСЛЕДУЕТСЯ ОТ nn.Module\n","class MyConvNet(nn.Module):\n","    def __init__(self):\n","        # вызов конструктора предка\n","        super(MyConvNet, self).__init__()\n","        # Ваш код здесь\n","        pass\n","\n","    def forward(self, x):\n","        # Ваш код здесь\n","        pass"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yWwW8daBmvR7","colab_type":"text"},"cell_type":"markdown","source":["Обучим:"]},{"metadata":{"id":"e393qPEBmvR7","colab_type":"code","colab":{}},"cell_type":"code","source":["from tqdm import tqdm_notebook"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EGOjA5ABmvR-","colab_type":"code","colab":{}},"cell_type":"code","source":["# пример взят из официального туториала: \n","# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","\n","net = MyConvNet()\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","learning_rate = 1e-4\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","\n","# итерируемся\n","for epoch in tqdm_notebook(range(3)):\n","\n","    running_loss = 0.0\n","    for i, batch in enumerate(tqdm_notebook(trainloader)):\n","        # так получаем текущий батч\n","        X_batch, y_batch = batch\n","        \n","        # РАЗВОРАЧИВАЕМ КАРТИНКУ В СТРОКУ\n","        X_batch = X_batch.view(4, -1)\n","\n","        # обнуляем веса\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        y_pred = net(X_batch)\n","        loss = loss_fn(y_pred, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # выведем текущий loss\n","        running_loss += loss.item()\n","        # выводем качество каждые 2000 батчей\n","        if i % 2000 == 1999:\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Обучение закончено')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u4doogQbmvSA","colab_type":"text"},"cell_type":"markdown","source":["Посмотрим на accuracy на тестовом датасете:"]},{"metadata":{"id":"VEzyCJHXmvSA","colab_type":"code","colab":{}},"cell_type":"code","source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        y_pred = net(images.view(4, -1))\n","        _, predicted = torch.max(y_pred, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(10):\n","    print('Accuracy of %5s : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C4OF55kMmvSE","colab_type":"text"},"cell_type":"markdown","source":["Как думаете, этого достаточно?"]},{"metadata":{"id":"F__l8jHsmvSF","colab_type":"text"},"cell_type":"markdown","source":["### Задача 3  \n","\n","Улучшите свёрточную нейросеть: поэкспериментируйте с архитектурой (количество слоёв, порядок слоёв), с гиперпараметрами слоёв (размеры kernel_size, размеры pooling'а, количество kernel'ов в свёрточном слое) и с гиперпараметрами, указанными в \"Компоненты нейросети\" (см. памятку выше)."]},{"metadata":{"id":"moepyKFemvSG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Ваш код здесь"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nwz2zvrSmvSJ","colab_type":"text"},"cell_type":"markdown","source":["(Ожидаемый результат -- скорее всего, сходу Вам не удастся выжать из Вашей сетки больше, чем ~70% accuracy (в среднем по всем классам). Если это что-то в этом районе - Вы хорошо постарались)."]},{"metadata":{"id":"BIIpG-8lmvSK","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"]},{"metadata":{"id":"cxjnt47smvSO","colab_type":"text"},"cell_type":"markdown","source":["1). *Примеры написания нейросетей на PyTorch (офийиальные туториалы) (на английском): https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples  \n","https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*"]},{"metadata":{"id":"s0OoUDBDmvSP","colab_type":"text"},"cell_type":"markdown","source":["2). ***Один из самых подробных и полных курсов по deep learning на данный момент - это курс Стэнфордского Университета (он вообще сейчас один из лидеров в области ИИ, его выпускники работают в Google, Facebook, Amazon, Microsoft, в стартапах в Кремниевой долине):  http://cs231n.github.io/***  "]},{"metadata":{"id":"lfCLur8VmvSR","colab_type":"text"},"cell_type":"markdown","source":["3). Практически исчерпывающая информация по основам свёрточных нейросетей (из cs231n) (на английском):  \n","\n","http://cs231n.github.io/convolutional-networks/  \n","http://cs231n.github.io/understanding-cnn/  \n","http://cs231n.github.io/transfer-learning/"]},{"metadata":{"id":"9cYDmcZxmvSR","colab_type":"text"},"cell_type":"markdown","source":["4). Видео о Computer Vision от Andrej Karpathy: https://www.youtube.com/watch?v=u6aEYuemt0M"]}]}