{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация дорожных знаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В этом ноутбуке будем классифицировать дорожные знаки Швеции. \n",
    "Вики: https://commons.wikimedia.org/wiki/Road_signs_in_Sweden\n",
    "### Рассмотрим:\n",
    "    - как загружать реальные данные в pytorch\n",
    "    - с какими проблемами можно столкнуться при работе с реальными данными\n",
    "    - способы проверки работоспособности сети(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим размер классифицируемых изображений\n",
    "PIC_SIZE = 50\n",
    "# Путь к предобработанным данным\n",
    "data_path = 'data//preprocessed//'\n",
    "# Путь, куда сохраним модель\n",
    "model_save_path = 'signs_classifier.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим класс-обёртку для нашего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SignsDataset(Dataset):\n",
    "    \"\"\"Road signs dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.signs_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Cоздаём массив label->index и массив index->label\n",
    "        self.labels = self.signs_frame['label'].unique()\n",
    "        self.label_indexes = {}\n",
    "        for i, label in enumerate(self.labels):\n",
    "            self.label_indexes[label] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Загрузим изображение и приведём к размеру 50х50\n",
    "        # Названия файлов лежат в self.sings_frame\n",
    "        # На выходе ожидается ровно одно изображение\n",
    "        \n",
    "        ## ВАШ КОД ЗДЕСЬ\n",
    "        image = \n",
    "        \n",
    "        ###############################################################################\n",
    "        \n",
    "        # В роли ответа будем давать номер label\n",
    "        # массив label->index создан в конструкторе \n",
    "        ## ВАШ КОД ЗДЕСЬ\n",
    "        label = \n",
    "        \n",
    "        # Применим преобразования изображения (например аугментацию)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим DataLoader'ы, облегчающие закрузку и сэмплинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Инициализируем загрузчик датасета (класс выше)\n",
    "dataset = SignsDataset(data_path + 'labels.csv', \n",
    "                       data_path, \n",
    "                       torchvision.transforms.ToTensor())\n",
    "\n",
    "indicies = np.arange(len(dataset))\n",
    "\n",
    "# Некоторые кадры идут подряд и почти совпадают\n",
    "# Нужно ли включать shuffle? Сделайте ваш выбор :)\n",
    "#np.random.seed(0)\n",
    "#np.random.shuffle(indicies)\n",
    "\n",
    "# Разбиение датасета на train и validation\n",
    "train_sampler = SubsetRandomSampler(indicies[:int(len(dataset)*0.5)])\n",
    "validation_sampler = SubsetRandomSampler(indicies[int(len(dataset)*0.5):])\n",
    "\n",
    "# DataLoader достаёт данные из dataset батчами\n",
    "signsTrainLoader = DataLoader(dataset, batch_size=16, sampler=train_sampler)\n",
    "signsValidationLoader = DataLoader(dataset, batch_size=32, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взглянем на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование из torch.Tensor к PIL Image(это функция)\n",
    "ToPIL = transforms.ToPILImage()\n",
    "\n",
    "# Посмотрим, что выдаёт одна итерация DataLoader\n",
    "# DataLoader является генератором, получите один элемент и выведите на экран\n",
    "\n",
    "\n",
    "## Ваш код здесь\n",
    "\n",
    "img =\n",
    "label_index = \n",
    "\n",
    "print(dataset.labels[label_index])\n",
    "plt.imshow(ToPIL(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные сильно несбалансированы (unbalanced dataset)\n",
    "### Задача\n",
    "    Взгляните на количество представителей каждого класса. Что не так?\n",
    "    К чему это может привести?\n",
    "    Подумайте о вариантах исправления проблемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.signs_frame\n",
    "classes_number = df['label'].nunique()\n",
    "print('Classes number:', classes_number)\n",
    "df.groupby('label')['file_name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаём и обучаем сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/269e3903f62eb2c4d13ac4c9ab979510010f8968/68747470733a2f2f7261772e6769746875622e636f6d2f746176677265656e2f6c616e647573655f636c617373696669636174696f6e2f6d61737465722f66696c652f636e6e2e706e673f7261773d74727565\" width=800, height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте сеть примерно следующей архитектуры:\n",
    "    conv -> max_pool -> conv -> fc -> fc -> fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс свёрточной нейронной сети\n",
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, class_number):\n",
    "        # вызов конструктора предка\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 3),\n",
    "        # которую будем подавать в сеть, больше ничего\n",
    "        # про входящие картинки знать не нужно\n",
    "        \n",
    "        \n",
    "        ## Ваш код здесь\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        ## Ваш код здесь\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём сеть\n",
    "cnn = SimpleConvNet(classes_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Взглянем на вывод\n",
    "batch = next(iter(signsTrainLoader))\n",
    "cnn(batch['image'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# С помощью этого увидим, как сеть обучалась\n",
    "history = {'loss':[], 'val_loss':[]}\n",
    "\n",
    "# Выбираем функцию потерь\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Выбираем алгоритм оптимизации и learning_rate\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Цикл обучения\n",
    "i = 0\n",
    "for epoch in tqdm_notebook(range(100)):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch in signsTrainLoader:\n",
    "        # Так получаем текущий батч\n",
    "        X_batch, y_batch = batch['image'], batch['label']\n",
    "        \n",
    "        # Обнуляем веса\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_pred = cnn(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        ###### Дальнейший код нужен для логирования #####\n",
    "        # Выведем текущий loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Пишем в лог каждые 50 батчей\n",
    "        if i % 50 == 49:\n",
    "            batch = next(iter(signsValidationLoader))\n",
    "            X_batch, y_batch = batch['image'], batch['label']\n",
    "            y_pred = cnn(X_batch)\n",
    "            \n",
    "            history['loss'].append(loss.item())\n",
    "            history['val_loss'].append(loss_fn(y_pred, y_batch).item())\n",
    "        \n",
    "        # Выведем качество каждые 1000 батчей\n",
    "        if i % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0\n",
    "        i += 1\n",
    "\n",
    "# Сохраним модель\n",
    "torch.save(cnn.state_dict(), model_save_path)\n",
    "print('Обучение закончено')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка обученной модели (для семинара)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = SimpleConvNet(classes_number)\n",
    "cnn.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начертим кривые обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Скользящее среднее\n",
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.clf()\n",
    "loss_values = smooth_curve(history['loss'])\n",
    "val_loss_values = smooth_curve(history['val_loss'])\n",
    "epochs = np.arange(len(loss_values))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "    Оцените, насколько сеть переобучилась\n",
    "    Что изменится, если применить \n",
    "        - аугментацию?\n",
    "        - регуляризацию?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Должно получиться так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выведем confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "    \n",
    "# Воспользуемся функцией из документации matplotlib, выводящей confusion matrix \n",
    "# Source https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    cm = cm.T\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    plt.figure(figsize=(16,11))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_all = torch.Tensor().long()\n",
    "predictions_all = torch.Tensor().long()\n",
    "\n",
    "# Пройдём по всему validation датасету и запишем ответы сети\n",
    "## Добавьте в y_test_all и predictions_all все истинные ответы и предсказания сети на Validation set'e,\n",
    "## чтобы на основе этих данных оценить точность сети (в вашем распоряжении signsValidationLoader)\n",
    "\n",
    "    ## Ваш код здесь\n",
    "\n",
    "## Функция torch.cat - аналог append для обычного списка в питоне\n",
    "## tensor = torch.cat((tensor, other_tensor), 0)       \n",
    "\n",
    "feature_names = signsTrainLoader.dataset.labels\n",
    "\n",
    "y_test_all = y_test_all.numpy()\n",
    "predictions_all = predictions_all.numpy()\n",
    "\n",
    "# Функция из sklearn, создаёт confusion матрицу\n",
    "cm = confusion_matrix(y_test_all, predictions_all, np.arange(classes_number))\n",
    "# Выведем её\n",
    "plot_confusion_matrix(cm, dataset.labels, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "    - какие выводы можно сделать из confusion matrix?\n",
    "    - как связаны результаты с распределением данных в датасете?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выведем точность для каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_correct = [0 for i in range(classes_number)]\n",
    "class_total = [0 for i in range(classes_number)]\n",
    "\n",
    "c = (predictions_all == y_test_all).squeeze()\n",
    "for i in range(len(predictions_all)):\n",
    "    label = predictions_all[i]            \n",
    "    class_correct[label] += c[i].item()\n",
    "    class_total[label] += 1\n",
    "\n",
    "print(class_total)\n",
    "\n",
    "for i in range(classes_number):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        (dataset.labels[i], (100 * class_correct[i] / class_total[i]) if class_total[i] != 0 else -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "    - какая связь между confusion matrix и accuracy для каждого класса?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим качество на отдельных кадрах из validation'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(signsValidationLoader))\n",
    "predictions = cnn(batch['image'])\n",
    "y_test = batch['label']\n",
    "\n",
    "\n",
    "#print(predictions, y_test)\n",
    "_, predictions = torch.max(predictions, 1)\n",
    "plt.imshow(ToPIL(batch['image'][0]))\n",
    "print('Gound-true:', dataset.labels[batch['label'][0]])\n",
    "print('Prediction:', dataset.labels[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее руководство по matplotlib: https://matplotlib.org/faq/usage_faq.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
