
# 10. Transfer Learning

Приветствуем Вас на **десятом** занятии нашего курса. Сегодня вы узнаете о методах обработки текста из гостевой лекции от специалиста из ABBYY, а также научитесь использовать предобученные модели и узнаете о Transfer Learning.

<p align=center>
  <img src="https://miro.medium.com/max/5252/1*Z11P-CjNYWBofEbmGQrptA.png" width=550>
</p>

### Лекция: Задачи в Natural Language Processing (ABBYY)

Иван Смуров, руководитель группы "Advanced NLP Research" в ABBYY, рассказывает о том, какие задачи существуют в NLP, почему там полезны нейросети и какие именно архитектуры сетей используются, включая самые современные подходы. В качестве примера рассмотрена задача поиска именованных сущностей (Named Entity Recognition, NER). [**Запись**](https://www.youtube.com/watch?v=6ys5F8W0Qbw) доступна по ссылке. 

### Семинар: Transfer learning

Необходимость каждый раз обучать нейросеть значительно затрудняет глубокое обучение, ведь чтобы получить хорошую сеть, нужно много данных и много вычислительных мощностей. Зачастую же нет ни того, ни другого. В таких случаях используются уже обученные на больших датасетах сети, а их веса только немного "подгоняются" под конкретную задачу. 

Подробнее о том, как экономить ресурсы и получать более высокое качество вы можете узнать из лекции-семинара по Transfer Learning. [**Запись**](https://www.youtube.com/watch?v=U12tq9l9xy8) доступна по ссылке, также в изучении Вам поможет jupyter-notebook: [**[seminar]transfer_learning.ipynb**](./[seminar]transfer_learning.ipynb) [<img src="https://colab.research.google.com/assets/colab-badge.svg" align="center">](https://colab.research.google.com/drive/1qZk0NgPIH1kzBbsfF61PBuyyGIAxUlFQ). 

Если же обучение моделей из ноутбука все равно занимает у вас много времени, можно использовать уже [обученные веса](https://drive.google.com/open?id=19knK-tbpwMaIeeCmmV-K-_ncKcxNYjJz).
